{
"cells": [
{
"cell_type": "markdown",
"id": "da78b18b",
"metadata": {},
"source": [
"### Code to find Table coordinates based on yolo"
]
},
{
"cell_type": "code",
"execution_count": 2,
"id": "3e92575c",
"metadata": {},
"outputs": [],
"source": [
"import cv2\n",
"import numpy as np\n",
"from ultralytics import YOLO\n",
"import torch"
]
},
{
"cell_type": "code",
"execution_count": 3,
"id": "ac70989e",
"metadata": {},
"outputs": [],
"source": [
"def yolo_on_video(model, video, start_frame, end_frame):\n",
"    cap = cv2.VideoCapture(video)\n",
"    cap.set(cv2.CAP_PROP_POS_FRAMES, start_frame)\n",
"\n",
"    frame_num = start_frame\n",
"    all_results = []\n",
"    while True:\n",
"        ret, frame = cap.read()\n",
"        if not ret or frame_num > end_frame:\n",
"            break\n",
"\n",
"        # Run YOLO inference\n",
"        if torch.cuda.is_available():\n",
"            results = model(frame, stream=True, device=\"cuda\")\n",
"        else:\n",
"            results = model(frame, stream=True, device=\"cpu\")\n",
"\n",
"        for r in results:\n",
"            all_results.append(r)\n",
"            annotated_frame = r.plot()\n",
"            cv2.imshow(\"YOLO Pose - Full\", annotated_frame)\n",
"\n",
"            keypoints = r.keypoints.cpu().numpy()  # (num_instances, num_keypoints, 3)\n",
"            if len(keypoints) > 0:\n",
"                table_corners = keypoints[0][:, :2]  # first instance, all keypoints, x,y only\n",
"                print(f\"Frame {frame_num}: Table corners (normalized): {table_corners}\")\n",
"\n",
"        frame_num += 1\n",
"\n",
"        # Exit on 'q'\n",
"        if cv2.waitKey(1) & 0xFF == ord(\"q\"):\n",
"            break\n",
"\n",
"    cap.release()\n",
"    cv2.destroyAllWindows()\n",
"    return all_results\n"
]
},
{
"cell_type": "code",
"execution_count": 4,
"id": "27539536",
"metadata": {},
"outputs": [],
"source": [
"def average_results(results):\n",
"    if len(results) == 0:\n",
"        print(\"No results to average\")\n",
"        return None\n",
"\n",
"    sum_corners = np.zeros((4, 2), dtype=np.float32)\n",
"    count = 0\n",
"\n",
"    for r in results:\n",
"        keypoints = r.keypoints.cpu().numpy()\n",
"        table_corners = None\n",
"\n",
"        # Case 1: use keypoints if available\n",
"        if len(keypoints) > 0:\n",
"            candidate = keypoints[0][:, :2]   # take first detection (x, y only)\n",
"            if candidate.shape == (4, 2):\n",
"                table_corners = candidate\n",
"\n",
"        # Case 2: fallback to bounding box\n",
"        if table_corners is None:\n",
"            if hasattr(r, \"boxes\") and len(r.boxes) > 0:\n",
"                box = r.boxes[0].xyxy.cpu().numpy()[0]  # (x1, y1, x2, y2)\n",
"                x1, y1, x2, y2 = box\n",
"                table_corners = np.array([\n",
"                    [x1, y1],  # top-left\n",
"                    [x2, y1],  # top-right\n",
"                    [x2, y2],  # bottom-right\n",
"                    [x1, y2],  # bottom-left\n",
"                ], dtype=np.float32)\n",
"\n",
"        # Add if we have valid corners\n",
"        if table_corners is not None and table_corners.shape == (4, 2):\n",
"            sum_corners += table_corners\n",
"            count += 1\n",
"\n",
"    if count == 0:\n",
"        return None\n",
"\n",
"    avg_corners = sum_corners / count\n",
"    return avg_corners\n"
]
},
{
"cell_type": "code",
"execution_count": 5,
"id": "66e81db3",
"metadata": {},
"outputs": [],
"source": [
"def annotate_frame_with_table(frame, table_corners):\n",
"    if table_corners is None:\n",
"        return frame  # nothing to draw\n",
"    \n",
"    # Convert to integer pixel coordinates\n",
"    pts = np.int32(table_corners).reshape((-1, 1, 2))\n",
"\n",
"    annotated = frame.copy()\n",
"    cv2.polylines(annotated, [pts], isClosed=True, color=(0, 255, 0), thickness=3)\n",
"\n",
"    return annotated\n"
]
},
{
"cell_type": "code",
"execution_count": 6,
"id": "3f211bb8",
"metadata": {},
"outputs": [
{
"ename": "FileNotFoundError",
"evalue": "[Errno 2] No such file or directory: 'TableDetection.pt'",
"output_type": "error",
"traceback": [
"\u001b[31m---------------------------------------------------------------------------\u001b[39m",
"\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
"\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      1\u001b[39m model_path = \u001b[33m\"\u001b[39m\u001b[33mTableDetection.pt\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m      2\u001b[39m video_path = \u001b[33m\"\u001b[39m\u001b[33m../Videos/game_1.mp4\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m model = \u001b[43mYOLO\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_path\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# load an official model\u001b[39;00m\n\u001b[32m      5\u001b[39m start_frame = \u001b[32m0\u001b[39m\n\u001b[32m      6\u001b[39m end_frame = \u001b[32m50\u001b[39m\n",
"\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\sreer\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\ultralytics\\models\\yolo\\model.py:81\u001b[39m, in \u001b[36mYOLO.__init__\u001b[39m\u001b[34m(self, model, task, verbose)\u001b[39m\n\u001b[32m     78\u001b[39m     \u001b[38;5;28mself\u001b[39m.\u001b[34m__dict__\u001b[39m = new_instance.\u001b[34m__dict__\u001b[39m\n\u001b[32m     79\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     80\u001b[39m     \u001b[38;5;66;03m# Continue with default YOLO initialization\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m81\u001b[39m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m=\u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     82\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m.model, \u001b[33m\"\u001b[39m\u001b[33mmodel\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mRTDETR\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.model.model[-\u001b[32m1\u001b[39m]._get_name():  \u001b[38;5;66;03m# if RTDETR head\u001b[39;00m\n\u001b[32m     83\u001b[39m         \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01multralytics\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m RTDETR\n",
"\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\sreer\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\ultralytics\\engine\\model.py:151\u001b[39m, in \u001b[36mModel.__init__\u001b[39m\u001b[34m(self, model, task, verbose)\u001b[39m\n\u001b[32m    149\u001b[39m     \u001b[38;5;28mself\u001b[39m._new(model, task=task, verbose=verbose)\n\u001b[32m    150\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m151\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_load\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    153\u001b[39m \u001b[38;5;66;03m# Delete super().training for accessing self.model.training\u001b[39;00m\n\u001b[32m    154\u001b[39m \u001b[38;5;28;01mdel\u001b[39;00m \u001b[38;5;28mself\u001b[39m.training\n",
"\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\sreer\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\ultralytics\\engine\\model.py:295\u001b[39m, in \u001b[36mModel._load\u001b[39m\u001b[34m(self, weights, task)\u001b[39m\n\u001b[32m    292\u001b[39m weights = checks.check_model_file_from_stem(weights)  \u001b[38;5;66;03m# add suffix, i.e. yolo11n -> yolo11n.pt\u001b[39;00m\n\u001b[32m    294\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(weights).rpartition(\u001b[33m\"\u001b[39m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m)[-\u001b[32m1\u001b[39m] == \u001b[33m\"\u001b[39m\u001b[33mpt\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m295\u001b[39m     \u001b[38;5;28mself\u001b[39m.model, \u001b[38;5;28mself\u001b[39m.ckpt = \u001b[43mattempt_load_one_weight\u001b[49m\u001b[43m(\u001b[49m\u001b[43mweights\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    296\u001b[39m     \u001b[38;5;28mself\u001b[39m.task = \u001b[38;5;28mself\u001b[39m.model.task\n\u001b[32m    297\u001b[39m     \u001b[38;5;28mself\u001b[39m.overrides = \u001b[38;5;28mself\u001b[39m.model.args = \u001b[38;5;28mself\u001b[39m._reset_ckpt_args(\u001b[38;5;28mself\u001b[39m.model.args)\n",
"\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\sreer\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\ultralytics\\nn\\tasks.py:1549\u001b[39m, in \u001b[36mattempt_load_one_weight\u001b[39m\u001b[34m(weight, device, inplace, fuse)\u001b[39m\n\u001b[32m   1535\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mattempt_load_one_weight\u001b[39m(weight, device=\u001b[38;5;28;01mNone\u001b[39;00m, inplace=\u001b[38;5;28;01mTrue\u001b[39;00m, fuse=\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[32m   1536\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   1537\u001b[39m \u001b[33;03m    Load a single model weights.\u001b[39;00m\n\u001b[32m   1538\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m   1547\u001b[39m \u001b[33;03m        ckpt (dict): Model checkpoint dictionary.\u001b[39;00m\n\u001b[32m   1548\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1549\u001b[39m     ckpt, weight = \u001b[43mtorch_safe_load\u001b[49m\u001b[43m(\u001b[49m\u001b[43mweight\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# load ckpt\u001b[39;00m\n\u001b[32m   1550\u001b[39m     args = {**DEFAULT_CFG_DICT, **(ckpt.get(\u001b[33m\"\u001b[39m\u001b[33mtrain_args\u001b[39m\u001b[33m\"\u001b[39m, {}))}  \u001b[38;5;66;03m# combine model and default args, preferring model args\u001b[39;00m\n\u001b[32m   1551\u001b[39m     model = (ckpt.get(\u001b[33m\"\u001b[39m\u001b[33mema\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m ckpt[\u001b[33m\"\u001b[39m\u001b[33mmodel\u001b[39m\u001b[33m\"\u001b[39m]).to(device).float()  \u001b[38;5;66;03m# FP32 model\u001b[39;00m\n",
"\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\sreer\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\ultralytics\\nn\\tasks.py:1447\u001b[39m, in \u001b[36mtorch_safe_load\u001b[39m\u001b[34m(weight, safe_only)\u001b[39m\n\u001b[32m   1445\u001b[39m                 ckpt = torch_load(f, pickle_module=safe_pickle)\n\u001b[32m   1446\u001b[39m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1447\u001b[39m             ckpt = \u001b[43mtorch_load\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmap_location\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcpu\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m   1449\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mModuleNotFoundError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# e.name is missing module name\u001b[39;00m\n\u001b[32m   1450\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m e.name == \u001b[33m\"\u001b[39m\u001b[33mmodels\u001b[39m\u001b[33m\"\u001b[39m:\n",
"\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\sreer\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\ultralytics\\utils\\patches.py:118\u001b[39m, in \u001b[36mtorch_load\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    115\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m TORCH_1_13 \u001b[38;5;129;01mand\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mweights_only\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m kwargs:\n\u001b[32m    116\u001b[39m     kwargs[\u001b[33m\"\u001b[39m\u001b[33mweights_only\u001b[39m\u001b[33m\"\u001b[39m] = \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m118\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
"\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\sreer\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\serialization.py:1484\u001b[39m, in \u001b[36mload\u001b[39m\u001b[34m(f, map_location, pickle_module, weights_only, mmap, **pickle_load_args)\u001b[39m\n\u001b[32m   1481\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mencoding\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m pickle_load_args.keys():\n\u001b[32m   1482\u001b[39m     pickle_load_args[\u001b[33m\"\u001b[39m\u001b[33mencoding\u001b[39m\u001b[33m\"\u001b[39m] = \u001b[33m\"\u001b[39m\u001b[33mutf-8\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m1484\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43m_open_file_like\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrb\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m opened_file:\n\u001b[32m   1485\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m _is_zipfile(opened_file):\n\u001b[32m   1486\u001b[39m         \u001b[38;5;66;03m# The zipfile reader is going to advance the current file position.\u001b[39;00m\n\u001b[32m   1487\u001b[39m         \u001b[38;5;66;03m# If we want to actually tail call to torch.jit.load, we need to\u001b[39;00m\n\u001b[32m   1488\u001b[39m         \u001b[38;5;66;03m# reset back to the original position.\u001b[39;00m\n\u001b[32m   1489\u001b[39m         orig_position = opened_file.tell()\n",
"\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\sreer\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\serialization.py:759\u001b[39m, in \u001b[36m_open_file_like\u001b[39m\u001b[34m(name_or_buffer, mode)\u001b[39m\n\u001b[32m    757\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_open_file_like\u001b[39m(name_or_buffer: FileLike, mode: \u001b[38;5;28mstr\u001b[39m) -> _opener[IO[\u001b[38;5;28mbytes\u001b[39m]]:\n\u001b[32m    758\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m _is_path(name_or_buffer):\n\u001b[32m--> \u001b[39m\u001b[32m759\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_open_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    760\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    761\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mw\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m mode:\n",
"\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\sreer\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\serialization.py:740\u001b[39m, in \u001b[36m_open_file.__init__\u001b[39m\u001b[34m(self, name, mode)\u001b[39m\n\u001b[32m    739\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, name: Union[\u001b[38;5;28mstr\u001b[39m, os.PathLike[\u001b[38;5;28mstr\u001b[39m]], mode: \u001b[38;5;28mstr\u001b[39m) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m740\u001b[39m     \u001b[38;5;28msuper\u001b[39m().\u001b[34m__init__\u001b[39m(\u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m)\n",
"\u001b[31mFileNotFoundError\u001b[39m: [Errno 2] No such file or directory: 'TableDetection.pt'"
]
}
],
"source": [
"model_path = \"TableDetection.pt\"\n",
"video_path = \"../Videos/game_1.mp4\"\n",
"\n",
"model = YOLO(model_path)  # load an official model\n",
"start_frame = 0\n",
"end_frame = 50\n",
"results = yolo_on_video(model, video_path, start_frame, end_frame)\n",
"avg_corners = average_results(results)\n",
"print(f\"Average Table corners (normalized): {avg_corners}\")\n",
"if avg_corners is not None:\n",
"    print(\"Corners being drawn:\", avg_corners)\n",
"    cap = cv2.VideoCapture(video_path)\n",
"    cap.set(cv2.CAP_PROP_POS_FRAMES, start_frame)\n",
"    ret, frame = cap.read()\n",
"    if ret:\n",
"        annotated = annotate_frame_with_table(frame, avg_corners)\n",
"        cv2.imshow(\"Average Table Position\", annotated)\n",
"        cv2.waitKey(0)\n",
"    cap.release()\n",
"    cv2.destroyAllWindows()\n",
"else:\n",
"    print(\"No valid table corners detected in any frame.\")"
]
},
{
"cell_type": "code",
"execution_count": 17,
"id": "bc450b8f",
"metadata": {},
"outputs": [
{
"name": "stdout",
"output_type": "stream",
"text": [
"Sum of squared errors: 4094\n"
]
}
],
"source": [
"model_corners = [[353.24, 494.26], [353.24, 679.19], [1431.2, 679.19], [1431.2, 494.26]]\n",
"model_corners1 = [[495, 501], [263, 657], [1457, 692], [1305, 524]]\n",
"actual_corners = [[509, 525], [303, 644], [1437, 664], [1293, 539]]\n",
"\n",
"model_corners_np = np.array(model_corners1)\n",
"actual_corners_np = np.array(actual_corners)\n",
"sse = np.sum((model_corners_np - actual_corners_np) ** 2)\n",
"print(\"Sum of squared errors:\", sse)"
]
}
],
"metadata": {
"kernelspec": {
"display_name": "Python 3",
"language": "python",
"name": "python3"
},
"language_info": {
"codemirror_mode": {
"name": "ipython",
"version": 3
},
"file_extension": ".py",
"mimetype": "text/x-python",
"name": "python",
"nbconvert_exporter": "python",
"pygments_lexer": "ipython3",
"version": "3.11.1"
}
},
"nbformat": 4,
"nbformat_minor": 5
}