{
<<<<<<< HEAD
 "cells": [
  {
   "cell_type": "markdown",
   "id": "da78b18b",
   "metadata": {},
   "source": [
    "### Code to find Table coordinates based on yolo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3e92575c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from ultralytics import YOLO\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ac70989e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def yolo_on_video(model, video, start_frame, end_frame):\n",
    "    cap = cv2.VideoCapture(video)\n",
    "    cap.set(cv2.CAP_PROP_POS_FRAMES, start_frame)\n",
    "\n",
    "    frame_num = start_frame\n",
    "    all_results = []\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret or frame_num > end_frame:\n",
    "            break\n",
    "\n",
    "        # Run YOLO inference\n",
    "        if torch.cuda.is_available():\n",
    "            results = model(frame, stream=True, device=\"cuda\")\n",
    "        else:\n",
    "            results = model(frame, stream=True, device=\"cpu\")\n",
    "\n",
    "        for r in results:\n",
    "            all_results.append(r)\n",
    "            annotated_frame = r.plot()\n",
    "            cv2.imshow(\"YOLO Pose - Full\", annotated_frame)\n",
    "\n",
    "            keypoints = r.keypoints.cpu().numpy()  # (num_instances, num_keypoints, 3)\n",
    "            if len(keypoints) > 0:\n",
    "                table_corners = keypoints[0][:, :2]  # first instance, all keypoints, x,y only\n",
    "                print(f\"Frame {frame_num}: Table corners (normalized): {table_corners}\")\n",
    "\n",
    "        frame_num += 1\n",
    "\n",
    "        # Exit on 'q'\n",
    "        if cv2.waitKey(1) & 0xFF == ord(\"q\"):\n",
    "            break\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "    return all_results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "27539536",
   "metadata": {},
   "outputs": [],
   "source": [
    "def average_results(results):\n",
    "    if len(results) == 0:\n",
    "        print(\"No results to average\")\n",
    "        return None\n",
    "\n",
    "    sum_corners = np.zeros((4, 2), dtype=np.float32)\n",
    "    count = 0\n",
    "\n",
    "    for r in results:\n",
    "        keypoints = r.keypoints.cpu().numpy()\n",
    "        table_corners = None\n",
    "\n",
    "        # Case 1: use keypoints if available\n",
    "        if len(keypoints) > 0:\n",
    "            candidate = keypoints[0][:, :2]   # take first detection (x, y only)\n",
    "            if candidate.shape == (4, 2):\n",
    "                table_corners = candidate\n",
    "\n",
    "        # Case 2: fallback to bounding box\n",
    "        if table_corners is None:\n",
    "            if hasattr(r, \"boxes\") and len(r.boxes) > 0:\n",
    "                box = r.boxes[0].xyxy.cpu().numpy()[0]  # (x1, y1, x2, y2)\n",
    "                x1, y1, x2, y2 = box\n",
    "                table_corners = np.array([\n",
    "                    [x1, y1],  # top-left\n",
    "                    [x2, y1],  # top-right\n",
    "                    [x2, y2],  # bottom-right\n",
    "                    [x1, y2],  # bottom-left\n",
    "                ], dtype=np.float32)\n",
    "\n",
    "        # Add if we have valid corners\n",
    "        if table_corners is not None and table_corners.shape == (4, 2):\n",
    "            sum_corners += table_corners\n",
    "            count += 1\n",
    "\n",
    "    if count == 0:\n",
    "        return None\n",
    "\n",
    "    avg_corners = sum_corners / count\n",
    "    return avg_corners\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "66e81db3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def annotate_frame_with_table(frame, table_corners):\n",
    "    if table_corners is None:\n",
    "        return frame  # nothing to draw\n",
    "    \n",
    "    # Convert to integer pixel coordinates\n",
    "    pts = np.int32(table_corners).reshape((-1, 1, 2))\n",
    "\n",
    "    annotated = frame.copy()\n",
    "    cv2.polylines(annotated, [pts], isClosed=True, color=(0, 255, 0), thickness=3)\n",
    "\n",
    "    return annotated\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3f211bb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 3 tables, 23.4ms\n",
      "Frame 0: Table corners (normalized): ultralytics.engine.results.Keypoints object with attributes:\n",
      "\n",
      "conf: array([[    0.54758,     0.45201]], dtype=float32)\n",
      "data: array([[[     1119.2,      603.22,     0.54758],\n",
      "        [     838.37,      838.99,     0.45201]]], dtype=float32)\n",
      "has_visible: True\n",
      "orig_shape: (1080, 1920)\n",
      "shape: (1, 2, 3)\n",
      "xy: array([[[     1119.2,      603.22],\n",
      "        [     838.37,      838.99]]], dtype=float32)\n",
      "xyn: array([[[    0.58291,     0.55854],\n",
      "        [    0.43665,     0.77684]]], dtype=float32)\n",
      "Speed: 4.7ms preprocess, 23.4ms inference, 7.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 tables, 20.3ms\n",
      "Frame 1: Table corners (normalized): ultralytics.engine.results.Keypoints object with attributes:\n",
      "\n",
      "conf: array([[    0.53165,     0.44068]], dtype=float32)\n",
      "data: array([[[     1019.6,      589.94,     0.53165],\n",
      "        [      770.6,      818.21,     0.44068]]], dtype=float32)\n",
      "has_visible: True\n",
      "orig_shape: (1080, 1920)\n",
      "shape: (1, 2, 3)\n",
      "xy: array([[[     1019.6,      589.94],\n",
      "        [      770.6,      818.21]]], dtype=float32)\n",
      "xyn: array([[[    0.53103,     0.54624],\n",
      "        [    0.40135,      0.7576]]], dtype=float32)\n",
      "Speed: 4.4ms preprocess, 20.3ms inference, 8.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 tables, 19.0ms\n",
      "Frame 2: Table corners (normalized): ultralytics.engine.results.Keypoints object with attributes:\n",
      "\n",
      "conf: array([[    0.51968,     0.49953]], dtype=float32)\n",
      "data: array([[[     1208.5,      632.29,     0.51968],\n",
      "        [     973.73,      816.46,     0.49953]]], dtype=float32)\n",
      "has_visible: True\n",
      "orig_shape: (1080, 1920)\n",
      "shape: (1, 2, 3)\n",
      "xy: array([[[     1208.5,      632.29],\n",
      "        [     973.73,      816.46]]], dtype=float32)\n",
      "xyn: array([[[    0.62943,     0.58545],\n",
      "        [    0.50715,     0.75598]]], dtype=float32)\n",
      "Speed: 4.2ms preprocess, 19.0ms inference, 6.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 tables, 18.0ms\n",
      "Frame 3: Table corners (normalized): ultralytics.engine.results.Keypoints object with attributes:\n",
      "\n",
      "conf: array([[    0.51698,      0.5045]], dtype=float32)\n",
      "data: array([[[     1209.9,      636.52,     0.51698],\n",
      "        [      969.4,      821.34,      0.5045]]], dtype=float32)\n",
      "has_visible: True\n",
      "orig_shape: (1080, 1920)\n",
      "shape: (1, 2, 3)\n",
      "xy: array([[[     1209.9,      636.52],\n",
      "        [      969.4,      821.34]]], dtype=float32)\n",
      "xyn: array([[[    0.63016,     0.58937],\n",
      "        [    0.50489,      0.7605]]], dtype=float32)\n",
      "Speed: 4.0ms preprocess, 18.0ms inference, 5.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 tables, 17.2ms\n",
      "Frame 4: Table corners (normalized): ultralytics.engine.results.Keypoints object with attributes:\n",
      "\n",
      "conf: array([[    0.51755,     0.49949]], dtype=float32)\n",
      "data: array([[[     1210.5,      632.38,     0.51755],\n",
      "        [     975.67,      817.08,     0.49949]]], dtype=float32)\n",
      "has_visible: True\n",
      "orig_shape: (1080, 1920)\n",
      "shape: (1, 2, 3)\n",
      "xy: array([[[     1210.5,      632.38],\n",
      "        [     975.67,      817.08]]], dtype=float32)\n",
      "xyn: array([[[    0.63046,     0.58553],\n",
      "        [    0.50816,     0.75656]]], dtype=float32)\n",
      "Speed: 7.1ms preprocess, 17.2ms inference, 4.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 tables, 17.4ms\n",
      "Frame 5: Table corners (normalized): ultralytics.engine.results.Keypoints object with attributes:\n",
      "\n",
      "conf: array([[    0.53414,      0.4437]], dtype=float32)\n",
      "data: array([[[     1021.9,      592.36,     0.53414],\n",
      "        [     759.33,      827.39,      0.4437]]], dtype=float32)\n",
      "has_visible: True\n",
      "orig_shape: (1080, 1920)\n",
      "shape: (1, 2, 3)\n",
      "xy: array([[[     1021.9,      592.36],\n",
      "        [     759.33,      827.39]]], dtype=float32)\n",
      "xyn: array([[[    0.53224,     0.54848],\n",
      "        [    0.39548,      0.7661]]], dtype=float32)\n",
      "Speed: 4.8ms preprocess, 17.4ms inference, 3.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 tables, 19.3ms\n",
      "Frame 6: Table corners (normalized): ultralytics.engine.results.Keypoints object with attributes:\n",
      "\n",
      "conf: array([[    0.54526,     0.45825]], dtype=float32)\n",
      "data: array([[[       1123,      603.65,     0.54526],\n",
      "        [     821.66,      856.48,     0.45825]]], dtype=float32)\n",
      "has_visible: True\n",
      "orig_shape: (1080, 1920)\n",
      "shape: (1, 2, 3)\n",
      "xy: array([[[       1123,      603.65],\n",
      "        [     821.66,      856.48]]], dtype=float32)\n",
      "xyn: array([[[    0.58492,     0.55893],\n",
      "        [    0.42795,     0.79304]]], dtype=float32)\n",
      "Speed: 4.6ms preprocess, 19.3ms inference, 4.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 tables, 17.8ms\n",
      "Frame 7: Table corners (normalized): ultralytics.engine.results.Keypoints object with attributes:\n",
      "\n",
      "conf: array([[    0.54689,      0.4501]], dtype=float32)\n",
      "data: array([[[     1124.9,      599.47,     0.54689],\n",
      "        [     824.85,      851.64,      0.4501]]], dtype=float32)\n",
      "has_visible: True\n",
      "orig_shape: (1080, 1920)\n",
      "shape: (1, 2, 3)\n",
      "xy: array([[[     1124.9,      599.47],\n",
      "        [     824.85,      851.64]]], dtype=float32)\n",
      "xyn: array([[[     0.5859,     0.55507],\n",
      "        [    0.42961,     0.78855]]], dtype=float32)\n",
      "Speed: 4.3ms preprocess, 17.8ms inference, 5.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 tables, 17.9ms\n",
      "Frame 8: Table corners (normalized): ultralytics.engine.results.Keypoints object with attributes:\n",
      "\n",
      "conf: array([[    0.54752,      0.4559]], dtype=float32)\n",
      "data: array([[[     1122.3,      600.85,     0.54752],\n",
      "        [     822.09,       854.1,      0.4559]]], dtype=float32)\n",
      "has_visible: True\n",
      "orig_shape: (1080, 1920)\n",
      "shape: (1, 2, 3)\n",
      "xy: array([[[     1122.3,      600.85],\n",
      "        [     822.09,       854.1]]], dtype=float32)\n",
      "xyn: array([[[    0.58451,     0.55634],\n",
      "        [    0.42817,     0.79083]]], dtype=float32)\n",
      "Speed: 4.7ms preprocess, 17.9ms inference, 3.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 tables, 17.5ms\n",
      "Frame 9: Table corners (normalized): ultralytics.engine.results.Keypoints object with attributes:\n",
      "\n",
      "conf: array([[    0.54644,      0.4505]], dtype=float32)\n",
      "data: array([[[     1119.1,      600.26,     0.54644],\n",
      "        [     833.69,      842.33,      0.4505]]], dtype=float32)\n",
      "has_visible: True\n",
      "orig_shape: (1080, 1920)\n",
      "shape: (1, 2, 3)\n",
      "xy: array([[[     1119.1,      600.26],\n",
      "        [     833.69,      842.33]]], dtype=float32)\n",
      "xyn: array([[[    0.58284,      0.5558],\n",
      "        [    0.43421,     0.77994]]], dtype=float32)\n",
      "Speed: 4.1ms preprocess, 17.5ms inference, 3.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 tables, 17.5ms\n",
      "Frame 10: Table corners (normalized): ultralytics.engine.results.Keypoints object with attributes:\n",
      "\n",
      "conf: array([[    0.55293,     0.45418]], dtype=float32)\n",
      "data: array([[[     1117.3,      602.84,     0.55293],\n",
      "        [     816.36,      851.92,     0.45418]]], dtype=float32)\n",
      "has_visible: True\n",
      "orig_shape: (1080, 1920)\n",
      "shape: (1, 2, 3)\n",
      "xy: array([[[     1117.3,      602.84],\n",
      "        [     816.36,      851.92]]], dtype=float32)\n",
      "xyn: array([[[    0.58193,     0.55819],\n",
      "        [    0.42519,     0.78881]]], dtype=float32)\n",
      "Speed: 4.7ms preprocess, 17.5ms inference, 3.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 tables, 17.4ms\n",
      "Frame 11: Table corners (normalized): ultralytics.engine.results.Keypoints object with attributes:\n",
      "\n",
      "conf: array([[    0.53892,      0.4408]], dtype=float32)\n",
      "data: array([[[     1019.3,      590.81,     0.53892],\n",
      "        [     750.92,      828.02,      0.4408]]], dtype=float32)\n",
      "has_visible: True\n",
      "orig_shape: (1080, 1920)\n",
      "shape: (1, 2, 3)\n",
      "xy: array([[[     1019.3,      590.81],\n",
      "        [     750.92,      828.02]]], dtype=float32)\n",
      "xyn: array([[[    0.53089,     0.54705],\n",
      "        [     0.3911,     0.76669]]], dtype=float32)\n",
      "Speed: 4.2ms preprocess, 17.4ms inference, 4.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 tables, 18.2ms\n",
      "Frame 12: Table corners (normalized): ultralytics.engine.results.Keypoints object with attributes:\n",
      "\n",
      "conf: array([[    0.53367,        0.45]], dtype=float32)\n",
      "data: array([[[     1019.7,      597.65,     0.53367],\n",
      "        [     752.18,      831.61,        0.45]]], dtype=float32)\n",
      "has_visible: True\n",
      "orig_shape: (1080, 1920)\n",
      "shape: (1, 2, 3)\n",
      "xy: array([[[     1019.7,      597.65],\n",
      "        [     752.18,      831.61]]], dtype=float32)\n",
      "xyn: array([[[    0.53108,     0.55338],\n",
      "        [    0.39176,     0.77001]]], dtype=float32)\n",
      "Speed: 4.1ms preprocess, 18.2ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 tables, 22.5ms\n",
      "Frame 13: Table corners (normalized): ultralytics.engine.results.Keypoints object with attributes:\n",
      "\n",
      "conf: array([[    0.53397,     0.46023]], dtype=float32)\n",
      "data: array([[[     1016.6,       605.5,     0.53397],\n",
      "        [     751.79,      829.81,     0.46023]]], dtype=float32)\n",
      "has_visible: True\n",
      "orig_shape: (1080, 1920)\n",
      "shape: (1, 2, 3)\n",
      "xy: array([[[     1016.6,       605.5],\n",
      "        [     751.79,      829.81]]], dtype=float32)\n",
      "xyn: array([[[    0.52949,     0.56064],\n",
      "        [    0.39155,     0.76834]]], dtype=float32)\n",
      "Speed: 5.0ms preprocess, 22.5ms inference, 3.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 tables, 17.6ms\n",
      "Frame 14: Table corners (normalized): ultralytics.engine.results.Keypoints object with attributes:\n",
      "\n",
      "conf: array([[    0.53723,     0.46709]], dtype=float32)\n",
      "data: array([[[     1019.4,      610.22,     0.53723],\n",
      "        [     727.35,      852.55,     0.46709]]], dtype=float32)\n",
      "has_visible: True\n",
      "orig_shape: (1080, 1920)\n",
      "shape: (1, 2, 3)\n",
      "xy: array([[[     1019.4,      610.22],\n",
      "        [     727.35,      852.55]]], dtype=float32)\n",
      "xyn: array([[[    0.53094,     0.56502],\n",
      "        [    0.37883,      0.7894]]], dtype=float32)\n",
      "Speed: 4.2ms preprocess, 17.6ms inference, 4.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 tables, 18.1ms\n",
      "Frame 15: Table corners (normalized): ultralytics.engine.results.Keypoints object with attributes:\n",
      "\n",
      "conf: array([[    0.53868,     0.47099]], dtype=float32)\n",
      "data: array([[[     1017.1,      612.63,     0.53868],\n",
      "        [     728.67,      846.86,     0.47099]]], dtype=float32)\n",
      "has_visible: True\n",
      "orig_shape: (1080, 1920)\n",
      "shape: (1, 2, 3)\n",
      "xy: array([[[     1017.1,      612.63],\n",
      "        [     728.67,      846.86]]], dtype=float32)\n",
      "xyn: array([[[    0.52972,     0.56725],\n",
      "        [    0.37951,     0.78413]]], dtype=float32)\n",
      "Speed: 5.4ms preprocess, 18.1ms inference, 4.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 tables, 18.1ms\n",
      "Frame 16: Table corners (normalized): ultralytics.engine.results.Keypoints object with attributes:\n",
      "\n",
      "conf: array([[    0.53257,     0.45778]], dtype=float32)\n",
      "data: array([[[     1019.1,       603.5,     0.53257],\n",
      "        [      746.5,      838.58,     0.45778]]], dtype=float32)\n",
      "has_visible: True\n",
      "orig_shape: (1080, 1920)\n",
      "shape: (1, 2, 3)\n",
      "xy: array([[[     1019.1,       603.5],\n",
      "        [      746.5,      838.58]]], dtype=float32)\n",
      "xyn: array([[[    0.53077,     0.55879],\n",
      "        [     0.3888,     0.77647]]], dtype=float32)\n",
      "Speed: 6.0ms preprocess, 18.1ms inference, 3.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 tables, 17.7ms\n",
      "Frame 17: Table corners (normalized): ultralytics.engine.results.Keypoints object with attributes:\n",
      "\n",
      "conf: array([[    0.53483,     0.47211]], dtype=float32)\n",
      "data: array([[[       1019,      614.49,     0.53483],\n",
      "        [     733.29,      847.41,     0.47211]]], dtype=float32)\n",
      "has_visible: True\n",
      "orig_shape: (1080, 1920)\n",
      "shape: (1, 2, 3)\n",
      "xy: array([[[       1019,      614.49],\n",
      "        [     733.29,      847.41]]], dtype=float32)\n",
      "xyn: array([[[    0.53074,     0.56897],\n",
      "        [    0.38192,     0.78464]]], dtype=float32)\n",
      "Speed: 5.0ms preprocess, 17.7ms inference, 4.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 tables, 17.6ms\n",
      "Frame 18: Table corners (normalized): ultralytics.engine.results.Keypoints object with attributes:\n",
      "\n",
      "conf: array([[    0.54648,     0.46526]], dtype=float32)\n",
      "data: array([[[     1121.3,      606.48,     0.54648],\n",
      "        [     820.91,      853.08,     0.46526]]], dtype=float32)\n",
      "has_visible: True\n",
      "orig_shape: (1080, 1920)\n",
      "shape: (1, 2, 3)\n",
      "xy: array([[[     1121.3,      606.48],\n",
      "        [     820.91,      853.08]]], dtype=float32)\n",
      "xyn: array([[[    0.58399,     0.56155],\n",
      "        [    0.42756,     0.78988]]], dtype=float32)\n",
      "Speed: 4.9ms preprocess, 17.6ms inference, 3.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 tables, 18.1ms\n",
      "Frame 19: Table corners (normalized): ultralytics.engine.results.Keypoints object with attributes:\n",
      "\n",
      "conf: array([[    0.53661,     0.45927]], dtype=float32)\n",
      "data: array([[[     1017.5,       606.8,     0.53661],\n",
      "        [     741.87,      841.71,     0.45927]]], dtype=float32)\n",
      "has_visible: True\n",
      "orig_shape: (1080, 1920)\n",
      "shape: (1, 2, 3)\n",
      "xy: array([[[     1017.5,       606.8],\n",
      "        [     741.87,      841.71]]], dtype=float32)\n",
      "xyn: array([[[    0.52995,     0.56185],\n",
      "        [    0.38639,     0.77936]]], dtype=float32)\n",
      "Speed: 4.9ms preprocess, 18.1ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 tables, 17.6ms\n",
      "Frame 20: Table corners (normalized): ultralytics.engine.results.Keypoints object with attributes:\n",
      "\n",
      "conf: array([[     0.5439,      0.4564]], dtype=float32)\n",
      "data: array([[[     1016.4,      606.09,      0.5439],\n",
      "        [     739.09,      836.89,      0.4564]]], dtype=float32)\n",
      "has_visible: True\n",
      "orig_shape: (1080, 1920)\n",
      "shape: (1, 2, 3)\n",
      "xy: array([[[     1016.4,      606.09],\n",
      "        [     739.09,      836.89]]], dtype=float32)\n",
      "xyn: array([[[    0.52936,     0.56119],\n",
      "        [    0.38494,      0.7749]]], dtype=float32)\n",
      "Speed: 6.2ms preprocess, 17.6ms inference, 3.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 tables, 18.1ms\n",
      "Frame 21: Table corners (normalized): ultralytics.engine.results.Keypoints object with attributes:\n",
      "\n",
      "conf: array([[    0.54055,     0.47352]], dtype=float32)\n",
      "data: array([[[     1014.8,      616.37,     0.54055],\n",
      "        [     729.86,      848.32,     0.47352]]], dtype=float32)\n",
      "has_visible: True\n",
      "orig_shape: (1080, 1920)\n",
      "shape: (1, 2, 3)\n",
      "xy: array([[[     1014.8,      616.37],\n",
      "        [     729.86,      848.32]]], dtype=float32)\n",
      "xyn: array([[[    0.52856,     0.57072],\n",
      "        [    0.38013,     0.78548]]], dtype=float32)\n",
      "Speed: 5.9ms preprocess, 18.1ms inference, 3.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 tables, 17.7ms\n",
      "Frame 22: Table corners (normalized): ultralytics.engine.results.Keypoints object with attributes:\n",
      "\n",
      "conf: array([[    0.53879,      0.4662]], dtype=float32)\n",
      "data: array([[[     1018.4,      610.15,     0.53879],\n",
      "        [     735.03,      847.07,      0.4662]]], dtype=float32)\n",
      "has_visible: True\n",
      "orig_shape: (1080, 1920)\n",
      "shape: (1, 2, 3)\n",
      "xy: array([[[     1018.4,      610.15],\n",
      "        [     735.03,      847.07]]], dtype=float32)\n",
      "xyn: array([[[     0.5304,     0.56496],\n",
      "        [    0.38283,     0.78433]]], dtype=float32)\n",
      "Speed: 4.6ms preprocess, 17.7ms inference, 4.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 tables, 19.7ms\n",
      "Frame 23: Table corners (normalized): ultralytics.engine.results.Keypoints object with attributes:\n",
      "\n",
      "conf: array([[    0.54321,     0.46856]], dtype=float32)\n",
      "data: array([[[     1019.7,       612.8,     0.54321],\n",
      "        [     731.04,      847.81,     0.46856]]], dtype=float32)\n",
      "has_visible: True\n",
      "orig_shape: (1080, 1920)\n",
      "shape: (1, 2, 3)\n",
      "xy: array([[[     1019.7,       612.8],\n",
      "        [     731.04,      847.81]]], dtype=float32)\n",
      "xyn: array([[[    0.53107,     0.56741],\n",
      "        [    0.38075,     0.78501]]], dtype=float32)\n",
      "Speed: 4.3ms preprocess, 19.7ms inference, 4.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 tables, 17.8ms\n",
      "Frame 24: Table corners (normalized): ultralytics.engine.results.Keypoints object with attributes:\n",
      "\n",
      "conf: array([[    0.54411,      0.4648]], dtype=float32)\n",
      "data: array([[[     1019.3,      611.81,     0.54411],\n",
      "        [     737.45,      839.87,      0.4648]]], dtype=float32)\n",
      "has_visible: True\n",
      "orig_shape: (1080, 1920)\n",
      "shape: (1, 2, 3)\n",
      "xy: array([[[     1019.3,      611.81],\n",
      "        [     737.45,      839.87]]], dtype=float32)\n",
      "xyn: array([[[    0.53088,     0.56649],\n",
      "        [    0.38409,     0.77765]]], dtype=float32)\n",
      "Speed: 4.3ms preprocess, 17.8ms inference, 5.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 tables, 17.9ms\n",
      "Frame 25: Table corners (normalized): ultralytics.engine.results.Keypoints object with attributes:\n",
      "\n",
      "conf: array([[    0.54002,     0.48155]], dtype=float32)\n",
      "data: array([[[     1012.1,       618.8,     0.54002],\n",
      "        [     726.56,      847.11,     0.48155]]], dtype=float32)\n",
      "has_visible: True\n",
      "orig_shape: (1080, 1920)\n",
      "shape: (1, 2, 3)\n",
      "xy: array([[[     1012.1,       618.8],\n",
      "        [     726.56,      847.11]]], dtype=float32)\n",
      "xyn: array([[[    0.52712,     0.57297],\n",
      "        [    0.37842,     0.78436]]], dtype=float32)\n",
      "Speed: 5.0ms preprocess, 17.9ms inference, 4.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 tables, 17.6ms\n",
      "Frame 26: Table corners (normalized): ultralytics.engine.results.Keypoints object with attributes:\n",
      "\n",
      "conf: array([[    0.54109,     0.46156]], dtype=float32)\n",
      "data: array([[[     1019.6,      605.85,     0.54109],\n",
      "        [     736.44,       838.5,     0.46156]]], dtype=float32)\n",
      "has_visible: True\n",
      "orig_shape: (1080, 1920)\n",
      "shape: (1, 2, 3)\n",
      "xy: array([[[     1019.6,      605.85],\n",
      "        [     736.44,       838.5]]], dtype=float32)\n",
      "xyn: array([[[    0.53105,     0.56097],\n",
      "        [    0.38356,     0.77639]]], dtype=float32)\n",
      "Speed: 4.8ms preprocess, 17.6ms inference, 4.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 tables, 18.1ms\n",
      "Frame 27: Table corners (normalized): ultralytics.engine.results.Keypoints object with attributes:\n",
      "\n",
      "conf: array([[    0.55252,     0.41188]], dtype=float32)\n",
      "data: array([[[       1028,       572.1,     0.55252],\n",
      "        [     736.09,      837.34,     0.41188]]], dtype=float32)\n",
      "has_visible: True\n",
      "orig_shape: (1080, 1920)\n",
      "shape: (1, 2, 3)\n",
      "xy: array([[[       1028,       572.1],\n",
      "        [     736.09,      837.34]]], dtype=float32)\n",
      "xyn: array([[[    0.53541,     0.52973],\n",
      "        [    0.38338,     0.77532]]], dtype=float32)\n",
      "Speed: 5.2ms preprocess, 18.1ms inference, 3.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 tables, 19.4ms\n",
      "Frame 28: Table corners (normalized): ultralytics.engine.results.Keypoints object with attributes:\n",
      "\n",
      "conf: array([[    0.56097,     0.41303]], dtype=float32)\n",
      "data: array([[[     1021.8,      574.75,     0.56097],\n",
      "        [     720.29,      839.73,     0.41303]]], dtype=float32)\n",
      "has_visible: True\n",
      "orig_shape: (1080, 1920)\n",
      "shape: (1, 2, 3)\n",
      "xy: array([[[     1021.8,      574.75],\n",
      "        [     720.29,      839.73]]], dtype=float32)\n",
      "xyn: array([[[    0.53219,     0.53218],\n",
      "        [    0.37515,     0.77753]]], dtype=float32)\n",
      "Speed: 7.1ms preprocess, 19.4ms inference, 3.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 tables, 18.4ms\n",
      "Frame 29: Table corners (normalized): ultralytics.engine.results.Keypoints object with attributes:\n",
      "\n",
      "conf: array([[    0.55936,     0.41412]], dtype=float32)\n",
      "data: array([[[     1026.1,      573.75,     0.55936],\n",
      "        [     714.67,      851.29,     0.41412]]], dtype=float32)\n",
      "has_visible: True\n",
      "orig_shape: (1080, 1920)\n",
      "shape: (1, 2, 3)\n",
      "xy: array([[[     1026.1,      573.75],\n",
      "        [     714.67,      851.29]]], dtype=float32)\n",
      "xyn: array([[[    0.53444,     0.53125],\n",
      "        [    0.37223,     0.78823]]], dtype=float32)\n",
      "Speed: 7.4ms preprocess, 18.4ms inference, 3.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 tables, 20.1ms\n",
      "Frame 30: Table corners (normalized): ultralytics.engine.results.Keypoints object with attributes:\n",
      "\n",
      "conf: array([[    0.57366,     0.40654]], dtype=float32)\n",
      "data: array([[[     1021.2,      572.05,     0.57366],\n",
      "        [     701.36,      850.22,     0.40654]]], dtype=float32)\n",
      "has_visible: True\n",
      "orig_shape: (1080, 1920)\n",
      "shape: (1, 2, 3)\n",
      "xy: array([[[     1021.2,      572.05],\n",
      "        [     701.36,      850.22]]], dtype=float32)\n",
      "xyn: array([[[    0.53187,     0.52967],\n",
      "        [    0.36529,     0.78725]]], dtype=float32)\n",
      "Speed: 6.1ms preprocess, 20.1ms inference, 4.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 tables, 19.5ms\n",
      "Frame 31: Table corners (normalized): ultralytics.engine.results.Keypoints object with attributes:\n",
      "\n",
      "conf: array([[    0.56715,     0.40705]], dtype=float32)\n",
      "data: array([[[     1025.1,      571.06,     0.56715],\n",
      "        [     706.54,      848.04,     0.40705]]], dtype=float32)\n",
      "has_visible: True\n",
      "orig_shape: (1080, 1920)\n",
      "shape: (1, 2, 3)\n",
      "xy: array([[[     1025.1,      571.06],\n",
      "        [     706.54,      848.04]]], dtype=float32)\n",
      "xyn: array([[[    0.53392,     0.52876],\n",
      "        [    0.36799,     0.78522]]], dtype=float32)\n",
      "Speed: 5.7ms preprocess, 19.5ms inference, 4.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 tables, 19.1ms\n",
      "Frame 32: Table corners (normalized): ultralytics.engine.results.Keypoints object with attributes:\n",
      "\n",
      "conf: array([[    0.57028,      0.4062]], dtype=float32)\n",
      "data: array([[[     1023.6,      572.09,     0.57028],\n",
      "        [     701.79,      847.23,      0.4062]]], dtype=float32)\n",
      "has_visible: True\n",
      "orig_shape: (1080, 1920)\n",
      "shape: (1, 2, 3)\n",
      "xy: array([[[     1023.6,      572.09],\n",
      "        [     701.79,      847.23]]], dtype=float32)\n",
      "xyn: array([[[    0.53314,     0.52971],\n",
      "        [    0.36552,     0.78447]]], dtype=float32)\n",
      "Speed: 6.0ms preprocess, 19.1ms inference, 4.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 tables, 19.8ms\n",
      "Frame 33: Table corners (normalized): ultralytics.engine.results.Keypoints object with attributes:\n",
      "\n",
      "conf: array([[    0.56072,     0.41525]], dtype=float32)\n",
      "data: array([[[     1023.1,      576.58,     0.56072],\n",
      "        [        716,      843.28,     0.41525]]], dtype=float32)\n",
      "has_visible: True\n",
      "orig_shape: (1080, 1920)\n",
      "shape: (1, 2, 3)\n",
      "xy: array([[[     1023.1,      576.58],\n",
      "        [        716,      843.28]]], dtype=float32)\n",
      "xyn: array([[[    0.53287,     0.53387],\n",
      "        [    0.37292,     0.78081]]], dtype=float32)\n",
      "Speed: 4.4ms preprocess, 19.8ms inference, 7.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 tables, 19.0ms\n",
      "Frame 34: Table corners (normalized): ultralytics.engine.results.Keypoints object with attributes:\n",
      "\n",
      "conf: array([[     0.5564,      0.4137]], dtype=float32)\n",
      "data: array([[[     1024.5,      574.06,      0.5564],\n",
      "        [     733.91,      836.09,      0.4137]]], dtype=float32)\n",
      "has_visible: True\n",
      "orig_shape: (1080, 1920)\n",
      "shape: (1, 2, 3)\n",
      "xy: array([[[     1024.5,      574.06],\n",
      "        [     733.91,      836.09]]], dtype=float32)\n",
      "xyn: array([[[    0.53359,     0.53154],\n",
      "        [    0.38225,     0.77415]]], dtype=float32)\n",
      "Speed: 6.2ms preprocess, 19.0ms inference, 3.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 tables, 19.8ms\n",
      "Frame 35: Table corners (normalized): ultralytics.engine.results.Keypoints object with attributes:\n",
      "\n",
      "conf: array([[    0.56527,     0.41278]], dtype=float32)\n",
      "data: array([[[     1021.9,      577.19,     0.56527],\n",
      "        [     721.82,      839.31,     0.41278]]], dtype=float32)\n",
      "has_visible: True\n",
      "orig_shape: (1080, 1920)\n",
      "shape: (1, 2, 3)\n",
      "xy: array([[[     1021.9,      577.19],\n",
      "        [     721.82,      839.31]]], dtype=float32)\n",
      "xyn: array([[[    0.53225,     0.53444],\n",
      "        [    0.37595,     0.77714]]], dtype=float32)\n",
      "Speed: 6.2ms preprocess, 19.8ms inference, 4.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 tables, 19.1ms\n",
      "Frame 36: Table corners (normalized): ultralytics.engine.results.Keypoints object with attributes:\n",
      "\n",
      "conf: array([[    0.54936,     0.43153]], dtype=float32)\n",
      "data: array([[[     1020.7,      586.92,     0.54936],\n",
      "        [     739.97,       830.9,     0.43153]]], dtype=float32)\n",
      "has_visible: True\n",
      "orig_shape: (1080, 1920)\n",
      "shape: (1, 2, 3)\n",
      "xy: array([[[     1020.7,      586.92],\n",
      "        [     739.97,       830.9]]], dtype=float32)\n",
      "xyn: array([[[     0.5316,     0.54344],\n",
      "        [     0.3854,     0.76935]]], dtype=float32)\n",
      "Speed: 4.4ms preprocess, 19.1ms inference, 4.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 tables, 18.9ms\n",
      "Frame 37: Table corners (normalized): ultralytics.engine.results.Keypoints object with attributes:\n",
      "\n",
      "conf: array([[    0.54805,     0.42649]], dtype=float32)\n",
      "data: array([[[       1023,         583,     0.54805],\n",
      "        [     741.76,      830.98,     0.42649]]], dtype=float32)\n",
      "has_visible: True\n",
      "orig_shape: (1080, 1920)\n",
      "shape: (1, 2, 3)\n",
      "xy: array([[[       1023,         583],\n",
      "        [     741.76,      830.98]]], dtype=float32)\n",
      "xyn: array([[[    0.53279,     0.53982],\n",
      "        [    0.38633,     0.76943]]], dtype=float32)\n",
      "Speed: 4.4ms preprocess, 18.9ms inference, 4.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 tables, 20.2ms\n",
      "Frame 38: Table corners (normalized): ultralytics.engine.results.Keypoints object with attributes:\n",
      "\n",
      "conf: array([[    0.55735,     0.41925]], dtype=float32)\n",
      "data: array([[[     1020.9,      580.91,     0.55735],\n",
      "        [     738.27,       826.3,     0.41925]]], dtype=float32)\n",
      "has_visible: True\n",
      "orig_shape: (1080, 1920)\n",
      "shape: (1, 2, 3)\n",
      "xy: array([[[     1020.9,      580.91],\n",
      "        [     738.27,       826.3]]], dtype=float32)\n",
      "xyn: array([[[    0.53171,     0.53788],\n",
      "        [    0.38451,     0.76509]]], dtype=float32)\n",
      "Speed: 5.3ms preprocess, 20.2ms inference, 4.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 tables, 20.6ms\n",
      "Frame 39: Table corners (normalized): ultralytics.engine.results.Keypoints object with attributes:\n",
      "\n",
      "conf: array([[    0.55848,     0.42326]], dtype=float32)\n",
      "data: array([[[       1021,      584.75,     0.55848],\n",
      "        [     729.89,      832.48,     0.42326]]], dtype=float32)\n",
      "has_visible: True\n",
      "orig_shape: (1080, 1920)\n",
      "shape: (1, 2, 3)\n",
      "xy: array([[[       1021,      584.75],\n",
      "        [     729.89,      832.48]]], dtype=float32)\n",
      "xyn: array([[[    0.53179,     0.54143],\n",
      "        [    0.38015,     0.77081]]], dtype=float32)\n",
      "Speed: 4.9ms preprocess, 20.6ms inference, 4.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 tables, 20.4ms\n",
      "Frame 40: Table corners (normalized): ultralytics.engine.results.Keypoints object with attributes:\n",
      "\n",
      "conf: array([[    0.54891,     0.43643]], dtype=float32)\n",
      "data: array([[[     1022.5,      590.46,     0.54891],\n",
      "        [     736.65,      834.61,     0.43643]]], dtype=float32)\n",
      "has_visible: True\n",
      "orig_shape: (1080, 1920)\n",
      "shape: (1, 2, 3)\n",
      "xy: array([[[     1022.5,      590.46],\n",
      "        [     736.65,      834.61]]], dtype=float32)\n",
      "xyn: array([[[    0.53257,     0.54673],\n",
      "        [    0.38367,     0.77278]]], dtype=float32)\n",
      "Speed: 4.4ms preprocess, 20.4ms inference, 4.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 tables, 19.1ms\n",
      "Frame 41: Table corners (normalized): ultralytics.engine.results.Keypoints object with attributes:\n",
      "\n",
      "conf: array([[    0.55324,     0.44093]], dtype=float32)\n",
      "data: array([[[     1023.5,      594.71,     0.55324],\n",
      "        [     727.56,      839.93,     0.44093]]], dtype=float32)\n",
      "has_visible: True\n",
      "orig_shape: (1080, 1920)\n",
      "shape: (1, 2, 3)\n",
      "xy: array([[[     1023.5,      594.71],\n",
      "        [     727.56,      839.93]]], dtype=float32)\n",
      "xyn: array([[[    0.53305,     0.55066],\n",
      "        [    0.37894,     0.77771]]], dtype=float32)\n",
      "Speed: 4.5ms preprocess, 19.1ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 table, 19.0ms\n",
      "Frame 42: Table corners (normalized): ultralytics.engine.results.Keypoints object with attributes:\n",
      "\n",
      "conf: array([[    0.55299,     0.42703]], dtype=float32)\n",
      "data: array([[[     1021.6,      584.21,     0.55299],\n",
      "        [     740.34,      826.73,     0.42703]]], dtype=float32)\n",
      "has_visible: True\n",
      "orig_shape: (1080, 1920)\n",
      "shape: (1, 2, 3)\n",
      "xy: array([[[     1021.6,      584.21],\n",
      "        [     740.34,      826.73]]], dtype=float32)\n",
      "xyn: array([[[     0.5321,     0.54094],\n",
      "        [    0.38559,     0.76549]]], dtype=float32)\n",
      "Speed: 4.6ms preprocess, 19.0ms inference, 3.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 tables, 19.5ms\n",
      "Frame 43: Table corners (normalized): ultralytics.engine.results.Keypoints object with attributes:\n",
      "\n",
      "conf: array([[    0.55321,     0.42871]], dtype=float32)\n",
      "data: array([[[     1023.1,       585.1,     0.55321],\n",
      "        [     739.44,      826.19,     0.42871]]], dtype=float32)\n",
      "has_visible: True\n",
      "orig_shape: (1080, 1920)\n",
      "shape: (1, 2, 3)\n",
      "xy: array([[[     1023.1,       585.1],\n",
      "        [     739.44,      826.19]]], dtype=float32)\n",
      "xyn: array([[[    0.53286,     0.54176],\n",
      "        [    0.38513,     0.76499]]], dtype=float32)\n",
      "Speed: 4.5ms preprocess, 19.5ms inference, 4.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 tables, 19.3ms\n",
      "Frame 44: Table corners (normalized): ultralytics.engine.results.Keypoints object with attributes:\n",
      "\n",
      "conf: array([[    0.55914,     0.43117]], dtype=float32)\n",
      "data: array([[[     1023.1,      588.12,     0.55914],\n",
      "        [     724.19,      837.77,     0.43117]]], dtype=float32)\n",
      "has_visible: True\n",
      "orig_shape: (1080, 1920)\n",
      "shape: (1, 2, 3)\n",
      "xy: array([[[     1023.1,      588.12],\n",
      "        [     724.19,      837.77]]], dtype=float32)\n",
      "xyn: array([[[    0.53286,     0.54455],\n",
      "        [    0.37718,     0.77571]]], dtype=float32)\n",
      "Speed: 4.6ms preprocess, 19.3ms inference, 4.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 tables, 19.4ms\n",
      "Frame 45: Table corners (normalized): ultralytics.engine.results.Keypoints object with attributes:\n",
      "\n",
      "conf: array([[     0.5559,     0.42033]], dtype=float32)\n",
      "data: array([[[     1022.8,      578.58,      0.5559],\n",
      "        [     743.92,      826.32,     0.42033]]], dtype=float32)\n",
      "has_visible: True\n",
      "orig_shape: (1080, 1920)\n",
      "shape: (1, 2, 3)\n",
      "xy: array([[[     1022.8,      578.58],\n",
      "        [     743.92,      826.32]]], dtype=float32)\n",
      "xyn: array([[[    0.53269,     0.53572],\n",
      "        [    0.38746,     0.76511]]], dtype=float32)\n",
      "Speed: 5.7ms preprocess, 19.4ms inference, 4.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 tables, 19.3ms\n",
      "Frame 46: Table corners (normalized): ultralytics.engine.results.Keypoints object with attributes:\n",
      "\n",
      "conf: array([[    0.55187,     0.43641]], dtype=float32)\n",
      "data: array([[[       1023,      589.59,     0.55187],\n",
      "        [     738.16,      834.25,     0.43641]]], dtype=float32)\n",
      "has_visible: True\n",
      "orig_shape: (1080, 1920)\n",
      "shape: (1, 2, 3)\n",
      "xy: array([[[       1023,      589.59],\n",
      "        [     738.16,      834.25]]], dtype=float32)\n",
      "xyn: array([[[    0.53279,     0.54592],\n",
      "        [    0.38446,     0.77245]]], dtype=float32)\n",
      "Speed: 4.3ms preprocess, 19.3ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 tables, 19.1ms\n",
      "Frame 47: Table corners (normalized): ultralytics.engine.results.Keypoints object with attributes:\n",
      "\n",
      "conf: array([[    0.55151,      0.4284]], dtype=float32)\n",
      "data: array([[[     1023.2,      583.12,     0.55151],\n",
      "        [      738.5,      833.33,      0.4284]]], dtype=float32)\n",
      "has_visible: True\n",
      "orig_shape: (1080, 1920)\n",
      "shape: (1, 2, 3)\n",
      "xy: array([[[     1023.2,      583.12],\n",
      "        [      738.5,      833.33]]], dtype=float32)\n",
      "xyn: array([[[    0.53289,     0.53993],\n",
      "        [    0.38464,      0.7716]]], dtype=float32)\n",
      "Speed: 4.7ms preprocess, 19.1ms inference, 4.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 tables, 20.5ms\n",
      "Frame 48: Table corners (normalized): ultralytics.engine.results.Keypoints object with attributes:\n",
      "\n",
      "conf: array([[     0.5483,     0.43657]], dtype=float32)\n",
      "data: array([[[     1021.9,      590.05,      0.5483],\n",
      "        [     741.29,      830.14,     0.43657]]], dtype=float32)\n",
      "has_visible: True\n",
      "orig_shape: (1080, 1920)\n",
      "shape: (1, 2, 3)\n",
      "xy: array([[[     1021.9,      590.05],\n",
      "        [     741.29,      830.14]]], dtype=float32)\n",
      "xyn: array([[[    0.53222,     0.54634],\n",
      "        [    0.38609,     0.76864]]], dtype=float32)\n",
      "Speed: 4.8ms preprocess, 20.5ms inference, 5.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 tables, 20.4ms\n",
      "Frame 49: Table corners (normalized): ultralytics.engine.results.Keypoints object with attributes:\n",
      "\n",
      "conf: array([[    0.55536,     0.42066]], dtype=float32)\n",
      "data: array([[[     1022.3,      580.04,     0.55536],\n",
      "        [     740.96,      827.33,     0.42066]]], dtype=float32)\n",
      "has_visible: True\n",
      "orig_shape: (1080, 1920)\n",
      "shape: (1, 2, 3)\n",
      "xy: array([[[     1022.3,      580.04],\n",
      "        [     740.96,      827.33]]], dtype=float32)\n",
      "xyn: array([[[    0.53244,     0.53708],\n",
      "        [    0.38592,     0.76604]]], dtype=float32)\n",
      "Speed: 5.5ms preprocess, 20.4ms inference, 4.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 tables, 20.5ms\n",
      "Frame 50: Table corners (normalized): ultralytics.engine.results.Keypoints object with attributes:\n",
      "\n",
      "conf: array([[    0.55338,     0.41469]], dtype=float32)\n",
      "data: array([[[       1022,      574.35,     0.55338],\n",
      "        [     752.91,      819.43,     0.41469]]], dtype=float32)\n",
      "has_visible: True\n",
      "orig_shape: (1080, 1920)\n",
      "shape: (1, 2, 3)\n",
      "xy: array([[[       1022,      574.35],\n",
      "        [     752.91,      819.43]]], dtype=float32)\n",
      "xyn: array([[[    0.53227,     0.53181],\n",
      "        [    0.39214,     0.75873]]], dtype=float32)\n",
      "Speed: 5.9ms preprocess, 20.5ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Average Table corners (normalized): [[     453.87      572.61]\n",
      " [     1487.3      572.61]\n",
      " [     1487.3       785.4]\n",
      " [     453.87       785.4]]\n",
      "Corners being drawn:\n",
      "(453.87, 572.61)\n",
      "(1487.33, 572.61)\n",
      "(1487.33, 785.40)\n",
      "(453.87, 785.40)\n"
     ]
    }
   ],
   "source": [
    "model_path = \"TableDetection.pt\"\n",
    "video_path = \"../Videos/game_5.mp4\"\n",
    "\n",
    "model = YOLO(model_path)  # load an official model\n",
    "start_frame = 0\n",
    "end_frame = 50\n",
    "results = yolo_on_video(model, video_path, start_frame, end_frame)\n",
    "avg_corners = average_results(results)\n",
    "print(f\"Average Table corners (normalized): {avg_corners}\")\n",
    "if avg_corners is not None:\n",
    "    print(\"Corners being drawn:\", )\n",
    "    for corner in avg_corners:\n",
    "        print(f\"({corner[0]:.2f}, {corner[1]:.2f})\")\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    cap.set(cv2.CAP_PROP_POS_FRAMES, start_frame)\n",
    "    ret, frame = cap.read()\n",
    "    if ret:\n",
    "        annotated = annotate_frame_with_table(frame, avg_corners)\n",
    "        cv2.imshow(\"Average Table Position\", annotated)\n",
    "        cv2.waitKey(0)\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "else:\n",
    "    print(\"No valid table corners detected in any frame.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc450b8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sum of squared errors: 4094\n"
     ]
    }
   ],
   "source": [
    "model_corners = [[353.24, 494.26], [353.24, 679.19], [1431.2, 679.19], [1431.2, 494.26]]\n",
    "model_corners1 = [[495, 501], [263, 657], [1457, 692], [1305, 524]]\n",
    "actual_corners = [[509, 525], [303, 644], [1437, 664], [1293, 539]]\n",
    "\n",
    "model_corners_np = np.array(model_corners1)\n",
    "actual_corners_np = np.array(actual_corners)\n",
    "sse = np.sum((model_corners_np - actual_corners_np) ** 2)\n",
    "print(\"Sum of squared errors:\", sse)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
=======
"cells": [
{
"cell_type": "markdown",
"id": "da78b18b",
"metadata": {},
"source": [
"### Code to find Table coordinates based on yolo"
]
},
{
"cell_type": "code",
"execution_count": 2,
"id": "3e92575c",
"metadata": {},
"outputs": [],
"source": [
"import cv2\n",
"import numpy as np\n",
"from ultralytics import YOLO\n",
"import torch"
]
},
{
"cell_type": "code",
"execution_count": 3,
"id": "ac70989e",
"metadata": {},
"outputs": [],
"source": [
"def yolo_on_video(model, video, start_frame, end_frame):\n",
"    cap = cv2.VideoCapture(video)\n",
"    cap.set(cv2.CAP_PROP_POS_FRAMES, start_frame)\n",
"\n",
"    frame_num = start_frame\n",
"    all_results = []\n",
"    while True:\n",
"        ret, frame = cap.read()\n",
"        if not ret or frame_num > end_frame:\n",
"            break\n",
"\n",
"        # Run YOLO inference\n",
"        if torch.cuda.is_available():\n",
"            results = model(frame, stream=True, device=\"cuda\")\n",
"        else:\n",
"            results = model(frame, stream=True, device=\"cpu\")\n",
"\n",
"        for r in results:\n",
"            all_results.append(r)\n",
"            annotated_frame = r.plot()\n",
"            cv2.imshow(\"YOLO Pose - Full\", annotated_frame)\n",
"\n",
"            keypoints = r.keypoints.cpu().numpy()  # (num_instances, num_keypoints, 3)\n",
"            if len(keypoints) > 0:\n",
"                table_corners = keypoints[0][:, :2]  # first instance, all keypoints, x,y only\n",
"                print(f\"Frame {frame_num}: Table corners (normalized): {table_corners}\")\n",
"\n",
"        frame_num += 1\n",
"\n",
"        # Exit on 'q'\n",
"        if cv2.waitKey(1) & 0xFF == ord(\"q\"):\n",
"            break\n",
"\n",
"    cap.release()\n",
"    cv2.destroyAllWindows()\n",
"    return all_results\n"
]
},
{
"cell_type": "code",
"execution_count": 4,
"id": "27539536",
"metadata": {},
"outputs": [],
"source": [
"def average_results(results):\n",
"    if len(results) == 0:\n",
"        print(\"No results to average\")\n",
"        return None\n",
"\n",
"    sum_corners = np.zeros((4, 2), dtype=np.float32)\n",
"    count = 0\n",
"\n",
"    for r in results:\n",
"        keypoints = r.keypoints.cpu().numpy()\n",
"        table_corners = None\n",
"\n",
"        # Case 1: use keypoints if available\n",
"        if len(keypoints) > 0:\n",
"            candidate = keypoints[0][:, :2]   # take first detection (x, y only)\n",
"            if candidate.shape == (4, 2):\n",
"                table_corners = candidate\n",
"\n",
"        # Case 2: fallback to bounding box\n",
"        if table_corners is None:\n",
"            if hasattr(r, \"boxes\") and len(r.boxes) > 0:\n",
"                box = r.boxes[0].xyxy.cpu().numpy()[0]  # (x1, y1, x2, y2)\n",
"                x1, y1, x2, y2 = box\n",
"                table_corners = np.array([\n",
"                    [x1, y1],  # top-left\n",
"                    [x2, y1],  # top-right\n",
"                    [x2, y2],  # bottom-right\n",
"                    [x1, y2],  # bottom-left\n",
"                ], dtype=np.float32)\n",
"\n",
"        # Add if we have valid corners\n",
"        if table_corners is not None and table_corners.shape == (4, 2):\n",
"            sum_corners += table_corners\n",
"            count += 1\n",
"\n",
"    if count == 0:\n",
"        return None\n",
"\n",
"    avg_corners = sum_corners / count\n",
"    return avg_corners\n"
]
},
{
"cell_type": "code",
"execution_count": 5,
"id": "66e81db3",
"metadata": {},
"outputs": [],
"source": [
"def annotate_frame_with_table(frame, table_corners):\n",
"    if table_corners is None:\n",
"        return frame  # nothing to draw\n",
"    \n",
"    # Convert to integer pixel coordinates\n",
"    pts = np.int32(table_corners).reshape((-1, 1, 2))\n",
"\n",
"    annotated = frame.copy()\n",
"    cv2.polylines(annotated, [pts], isClosed=True, color=(0, 255, 0), thickness=3)\n",
"\n",
"    return annotated\n"
]
},
{
"cell_type": "code",
"execution_count": 6,
"id": "3f211bb8",
"metadata": {},
"outputs": [
{
"ename": "FileNotFoundError",
"evalue": "[Errno 2] No such file or directory: 'TableDetection.pt'",
"output_type": "error",
"traceback": [
"\u001b[31m---------------------------------------------------------------------------\u001b[39m",
"\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
"\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      1\u001b[39m model_path = \u001b[33m\"\u001b[39m\u001b[33mTableDetection.pt\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m      2\u001b[39m video_path = \u001b[33m\"\u001b[39m\u001b[33m../Videos/game_1.mp4\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m model = \u001b[43mYOLO\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_path\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# load an official model\u001b[39;00m\n\u001b[32m      5\u001b[39m start_frame = \u001b[32m0\u001b[39m\n\u001b[32m      6\u001b[39m end_frame = \u001b[32m50\u001b[39m\n",
"\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\sreer\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\ultralytics\\models\\yolo\\model.py:81\u001b[39m, in \u001b[36mYOLO.__init__\u001b[39m\u001b[34m(self, model, task, verbose)\u001b[39m\n\u001b[32m     78\u001b[39m     \u001b[38;5;28mself\u001b[39m.\u001b[34m__dict__\u001b[39m = new_instance.\u001b[34m__dict__\u001b[39m\n\u001b[32m     79\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     80\u001b[39m     \u001b[38;5;66;03m# Continue with default YOLO initialization\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m81\u001b[39m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m=\u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     82\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m.model, \u001b[33m\"\u001b[39m\u001b[33mmodel\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mRTDETR\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.model.model[-\u001b[32m1\u001b[39m]._get_name():  \u001b[38;5;66;03m# if RTDETR head\u001b[39;00m\n\u001b[32m     83\u001b[39m         \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01multralytics\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m RTDETR\n",
"\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\sreer\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\ultralytics\\engine\\model.py:151\u001b[39m, in \u001b[36mModel.__init__\u001b[39m\u001b[34m(self, model, task, verbose)\u001b[39m\n\u001b[32m    149\u001b[39m     \u001b[38;5;28mself\u001b[39m._new(model, task=task, verbose=verbose)\n\u001b[32m    150\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m151\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_load\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    153\u001b[39m \u001b[38;5;66;03m# Delete super().training for accessing self.model.training\u001b[39;00m\n\u001b[32m    154\u001b[39m \u001b[38;5;28;01mdel\u001b[39;00m \u001b[38;5;28mself\u001b[39m.training\n",
"\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\sreer\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\ultralytics\\engine\\model.py:295\u001b[39m, in \u001b[36mModel._load\u001b[39m\u001b[34m(self, weights, task)\u001b[39m\n\u001b[32m    292\u001b[39m weights = checks.check_model_file_from_stem(weights)  \u001b[38;5;66;03m# add suffix, i.e. yolo11n -> yolo11n.pt\u001b[39;00m\n\u001b[32m    294\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(weights).rpartition(\u001b[33m\"\u001b[39m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m)[-\u001b[32m1\u001b[39m] == \u001b[33m\"\u001b[39m\u001b[33mpt\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m295\u001b[39m     \u001b[38;5;28mself\u001b[39m.model, \u001b[38;5;28mself\u001b[39m.ckpt = \u001b[43mattempt_load_one_weight\u001b[49m\u001b[43m(\u001b[49m\u001b[43mweights\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    296\u001b[39m     \u001b[38;5;28mself\u001b[39m.task = \u001b[38;5;28mself\u001b[39m.model.task\n\u001b[32m    297\u001b[39m     \u001b[38;5;28mself\u001b[39m.overrides = \u001b[38;5;28mself\u001b[39m.model.args = \u001b[38;5;28mself\u001b[39m._reset_ckpt_args(\u001b[38;5;28mself\u001b[39m.model.args)\n",
"\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\sreer\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\ultralytics\\nn\\tasks.py:1549\u001b[39m, in \u001b[36mattempt_load_one_weight\u001b[39m\u001b[34m(weight, device, inplace, fuse)\u001b[39m\n\u001b[32m   1535\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mattempt_load_one_weight\u001b[39m(weight, device=\u001b[38;5;28;01mNone\u001b[39;00m, inplace=\u001b[38;5;28;01mTrue\u001b[39;00m, fuse=\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[32m   1536\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   1537\u001b[39m \u001b[33;03m    Load a single model weights.\u001b[39;00m\n\u001b[32m   1538\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m   1547\u001b[39m \u001b[33;03m        ckpt (dict): Model checkpoint dictionary.\u001b[39;00m\n\u001b[32m   1548\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1549\u001b[39m     ckpt, weight = \u001b[43mtorch_safe_load\u001b[49m\u001b[43m(\u001b[49m\u001b[43mweight\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# load ckpt\u001b[39;00m\n\u001b[32m   1550\u001b[39m     args = {**DEFAULT_CFG_DICT, **(ckpt.get(\u001b[33m\"\u001b[39m\u001b[33mtrain_args\u001b[39m\u001b[33m\"\u001b[39m, {}))}  \u001b[38;5;66;03m# combine model and default args, preferring model args\u001b[39;00m\n\u001b[32m   1551\u001b[39m     model = (ckpt.get(\u001b[33m\"\u001b[39m\u001b[33mema\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m ckpt[\u001b[33m\"\u001b[39m\u001b[33mmodel\u001b[39m\u001b[33m\"\u001b[39m]).to(device).float()  \u001b[38;5;66;03m# FP32 model\u001b[39;00m\n",
"\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\sreer\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\ultralytics\\nn\\tasks.py:1447\u001b[39m, in \u001b[36mtorch_safe_load\u001b[39m\u001b[34m(weight, safe_only)\u001b[39m\n\u001b[32m   1445\u001b[39m                 ckpt = torch_load(f, pickle_module=safe_pickle)\n\u001b[32m   1446\u001b[39m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1447\u001b[39m             ckpt = \u001b[43mtorch_load\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmap_location\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcpu\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m   1449\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mModuleNotFoundError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# e.name is missing module name\u001b[39;00m\n\u001b[32m   1450\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m e.name == \u001b[33m\"\u001b[39m\u001b[33mmodels\u001b[39m\u001b[33m\"\u001b[39m:\n",
"\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\sreer\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\ultralytics\\utils\\patches.py:118\u001b[39m, in \u001b[36mtorch_load\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    115\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m TORCH_1_13 \u001b[38;5;129;01mand\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mweights_only\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m kwargs:\n\u001b[32m    116\u001b[39m     kwargs[\u001b[33m\"\u001b[39m\u001b[33mweights_only\u001b[39m\u001b[33m\"\u001b[39m] = \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m118\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
"\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\sreer\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\serialization.py:1484\u001b[39m, in \u001b[36mload\u001b[39m\u001b[34m(f, map_location, pickle_module, weights_only, mmap, **pickle_load_args)\u001b[39m\n\u001b[32m   1481\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mencoding\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m pickle_load_args.keys():\n\u001b[32m   1482\u001b[39m     pickle_load_args[\u001b[33m\"\u001b[39m\u001b[33mencoding\u001b[39m\u001b[33m\"\u001b[39m] = \u001b[33m\"\u001b[39m\u001b[33mutf-8\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m1484\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43m_open_file_like\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrb\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m opened_file:\n\u001b[32m   1485\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m _is_zipfile(opened_file):\n\u001b[32m   1486\u001b[39m         \u001b[38;5;66;03m# The zipfile reader is going to advance the current file position.\u001b[39;00m\n\u001b[32m   1487\u001b[39m         \u001b[38;5;66;03m# If we want to actually tail call to torch.jit.load, we need to\u001b[39;00m\n\u001b[32m   1488\u001b[39m         \u001b[38;5;66;03m# reset back to the original position.\u001b[39;00m\n\u001b[32m   1489\u001b[39m         orig_position = opened_file.tell()\n",
"\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\sreer\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\serialization.py:759\u001b[39m, in \u001b[36m_open_file_like\u001b[39m\u001b[34m(name_or_buffer, mode)\u001b[39m\n\u001b[32m    757\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_open_file_like\u001b[39m(name_or_buffer: FileLike, mode: \u001b[38;5;28mstr\u001b[39m) -> _opener[IO[\u001b[38;5;28mbytes\u001b[39m]]:\n\u001b[32m    758\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m _is_path(name_or_buffer):\n\u001b[32m--> \u001b[39m\u001b[32m759\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_open_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    760\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    761\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mw\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m mode:\n",
"\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\sreer\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\serialization.py:740\u001b[39m, in \u001b[36m_open_file.__init__\u001b[39m\u001b[34m(self, name, mode)\u001b[39m\n\u001b[32m    739\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, name: Union[\u001b[38;5;28mstr\u001b[39m, os.PathLike[\u001b[38;5;28mstr\u001b[39m]], mode: \u001b[38;5;28mstr\u001b[39m) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m740\u001b[39m     \u001b[38;5;28msuper\u001b[39m().\u001b[34m__init__\u001b[39m(\u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m)\n",
"\u001b[31mFileNotFoundError\u001b[39m: [Errno 2] No such file or directory: 'TableDetection.pt'"
]
>>>>>>> 5938a936a2e3e5b84813760049742fd3707166bd
}
],
"source": [
"model_path = \"TableDetection.pt\"\n",
"video_path = \"../Videos/game_1.mp4\"\n",
"\n",
"model = YOLO(model_path)  # load an official model\n",
"start_frame = 0\n",
"end_frame = 50\n",
"results = yolo_on_video(model, video_path, start_frame, end_frame)\n",
"avg_corners = average_results(results)\n",
"print(f\"Average Table corners (normalized): {avg_corners}\")\n",
"if avg_corners is not None:\n",
"    print(\"Corners being drawn:\", avg_corners)\n",
"    cap = cv2.VideoCapture(video_path)\n",
"    cap.set(cv2.CAP_PROP_POS_FRAMES, start_frame)\n",
"    ret, frame = cap.read()\n",
"    if ret:\n",
"        annotated = annotate_frame_with_table(frame, avg_corners)\n",
"        cv2.imshow(\"Average Table Position\", annotated)\n",
"        cv2.waitKey(0)\n",
"    cap.release()\n",
"    cv2.destroyAllWindows()\n",
"else:\n",
"    print(\"No valid table corners detected in any frame.\")"
]
},
{
"cell_type": "code",
"execution_count": 17,
"id": "bc450b8f",
"metadata": {},
"outputs": [
{
"name": "stdout",
"output_type": "stream",
"text": [
"Sum of squared errors: 4094\n"
]
}
],
"source": [
"model_corners = [[353.24, 494.26], [353.24, 679.19], [1431.2, 679.19], [1431.2, 494.26]]\n",
"model_corners1 = [[495, 501], [263, 657], [1457, 692], [1305, 524]]\n",
"actual_corners = [[509, 525], [303, 644], [1437, 664], [1293, 539]]\n",
"\n",
"model_corners_np = np.array(model_corners1)\n",
"actual_corners_np = np.array(actual_corners)\n",
"sse = np.sum((model_corners_np - actual_corners_np) ** 2)\n",
"print(\"Sum of squared errors:\", sse)"
]
}
],
"metadata": {
"kernelspec": {
"display_name": "Python 3",
"language": "python",
"name": "python3"
},
"language_info": {
"codemirror_mode": {
"name": "ipython",
"version": 3
},
"file_extension": ".py",
"mimetype": "text/x-python",
"name": "python",
"nbconvert_exporter": "python",
"pygments_lexer": "ipython3",
"version": "3.11.1"
}
},
"nbformat": 4,
"nbformat_minor": 5
}