\documentclass[conference]{IEEEtran}
\IEEEoverridecommandlockouts
% The preceding line is only needed to identify funding in the first footnote. If that is unneeded, please comment it out.
\usepackage{cite}
\usepackage{amsmath,amssymb,amsfonts}
\usepackage{algorithmic}
\usepackage{graphicx}
\usepackage{textcomp}
\usepackage{xcolor}
\usepackage{soul}
\usepackage{multirow}

\def\BibTeX{{\rm B\kern-.05em{\sc i\kern-.025em b}\kern-.08em
    T\kern-.1667em\lower.7ex\hbox{E}\kern-.125emX}}
\begin{document}

\title{Blackboard based Reasoning Framework for Explainable Table Tennis Analysis}




\author{
\makebox[0.32\textwidth][c]{
\begin{tabular}{c}
1\textsuperscript{st} Pramodini Padhmanabhan\\
\textit{Computer Science and Engineering}\\
\textit{PSG College of Technology}\\
Coimbatore, India\\
pramodheepa@gmail.com
\end{tabular}}
\hfill
\makebox[0.32\textwidth][c]{
\begin{tabular}{c}
2\textsuperscript{nd} Akash Shanmugaraj\\
\textit{Computer Science and Engineering}\\
\textit{PSG College of Technology}\\
Coimbatore, India\\
akashshanmugaraj@gmail.com
\end{tabular}}
\hfill
\makebox[0.32\textwidth][c]{
\begin{tabular}{c}
3\textsuperscript{rd} Sanjitha Rajakumar\\
\textit{Computer Science and Engineering}\\
\textit{PSG College of Technology}\\
Coimbatore, India\\
sanjitha20041234@gmail.com
\end{tabular}}\\[2ex]
\makebox[0.32\textwidth][c]{
\begin{tabular}{c}
4\textsuperscript{th} Sreeraghavan Ramamoorthy\\
\textit{Computer Science and Engineering}\\
\textit{PSG College of Technology}\\
Coimbatore, India\\
sreeraghavan2016@gmail.com
\end{tabular}}
\hfill
\makebox[0.32\textwidth][c]{
\begin{tabular}{c}
5\textsuperscript{th} Dwarkesh\\
\textit{Computer Science and Engineering}\\
\textit{PSG College of Technology}\\
Coimbatore, India\\
gurudwarkesh@gmail.com
\end{tabular}}
\hfill
\makebox[0.32\textwidth][c]{
\begin{tabular}{c}
6\textsuperscript{th} Mrs. K. Archana\\
\textit{Computer Science and Engineering}\\
\textit{PSG College of Technology}\\
Coimbatore, India\\
archanak2896@gmail.com
\end{tabular}}
}


\maketitle

\begin{abstract}
Reasoning models presently rely a lot on LLMs and LLM agents taking various roles.This has its advantages, but it requires a large number of tokens and computation. There are also other non-LLM based ways that provide intelligence such as various ML models that are specialized. 

Working with multiple specialized models together is a better way to obtain reasoning. This architecture facilitates flexible integration of diverse analysis components and minimizes redundant computation. A shared context layer aggregates module outputs for centralized LLM based querying and downstream applications such as visualization, summarization, and performance reporting. 

We demonstrate the applicability of the system in the domain of sports video analysis, using table tennis match footage as a case study. The proposed design generalizes well to other domains that require fine-grained and interpretable video understanding.


\end{abstract}

\begin{IEEEkeywords}
Blackboard architecture, multi-agent systems, explainable artificial intelligence, sports video analysis, trajectory estimation, depth estimation, autonomous learning
\end{IEEEkeywords}

\section{Introduction}
Video understanding needs extraction of various, diverse, and different insights like player positions, ball trajectory, player heat map, space point estimator etc. Current approaches try to perform the analysis in a single brute force approach using a large language model taking up a substantial amount of computing power and time, while also sacrificing on the specific task evaluation models accuracy and performance.
Recent advancements in machine learning have demonstrated that specialized models have greater performance and accuracy than general machine learning models. However, integrating multiple specialized models into a single reasoning system is challenging yet rewarding with its accuracy and performance. Current systems either use general LLMs that leave out the performance and attention to detail that can be achieved by specialized systems, or use application specific rigidly integrated pipelines that don’t work in generalized domains. This highlights the gap between efficient specialized model systems and the flexible, interpretable reasoning system.
With this we present a modular intelligence architecture that couples specialized ML models with reasoning models. This system uses blackboard architecture in the backend to accumulate all data to a central point, from which the independent model data can be retrieved. We use a publish subscribe architecture to ensure only required models are run for any sequence. This reduces the amount of computation while maintaining explainability while allowing for flexible, multi model analysis.
We check this architecture with the application of table tennis video analysis. The system uses specialized models for player detection, player heat map, ball tracking and ball trajectory estimation. These are integrated with the publish subscribe network and blackboard to generate insights
\section{Problem Statement}

This project will build a scalable Table Tennis Video Analysis system using deep‑learning models and efficient spatio‑temporal feature extractors to tally rally exchanges, pinpoint bounce locations, and produce player movement insights.

It uses the following core components - object detection, event segmentation, pose estimation, and sequence analysis. These components work together in a modular and agentic architecture, where each component functions as a semi-autonomous "agent" focused on a specialized task. Outputs from individual agents can be integrated to form higher-level insights such as:Provide point-by-point suggestions based on detected inefficiencies 

The agentic architecture also allows for fast extensibility without requiring re-engineering of any core systems


\section{Literature Survey}

\subsection{Trajectory Analysis}

Trajectory analysis depends on multiple data and image processing along with some deep learning models. Some efforts include metadata about the video and objects such as accelerometers to create more reliable information.\cite{pongball}.

\subsubsection{Workflow}

Trajectory analysis in sports follows a systematic multi-stage workflow beginning with data acquisition through high-speed cameras operating at 60-120 fps in synchronized multi-camera setups \cite{electronics14010027}. 

This is followed by object detection which employs models such as those in the YOLO family or TrackNetV2 \cite{electronics14010027}or ByteTrack with Kalman filtering to maintain temporal consistency. Subsequently, the ball detection and camera calibration is used to create 3D trajectories
\cite{pongball}.

\subsubsection{Models Used}

Primarily, they have used YOLOv4 and v11 for detecting the ball. Multiple cameras were also required \cite{electronics14010027}. Advanced reconstruction employs LSTM-based architectures featuring specialized networks: LSTM$\varepsilon$ for End-of-Trajectory prediction, LSTM\textsubscript{height} for vertical position estimation, and LSTM\textsubscript{refine} for trajectory smoothing.


\subsection{Player Heatmap}

Hass et al.,[], created a comprehensive player heatmap pipeline by combining deep learning models and some computer vision algorithms.\cite{haas2023heatmap}

\subsubsection{Workflow}

At first, the table was identified by using Hough transforms and some normal image processing techniques and algorithms. Next the players themselves were identified using Facebook’s Detectron2. The video was segmented into rallies, however it is not clear if that was automated or manual. The heatmap itself was generated by segmenting the play area into a grid and plotting the player locations onto the grid for each frame.\cite{haas2023heatmap}

\subsubsection{Models Used}

Detectron2 for player detection. Hough Transforms for table detection \cite{haas2023heatmap}.

\subsection{LLM Reasoning Architectures}
Earlier AI systems that separated memory, control, and knowledge were based on the Blackboard Model \cite{hanllm}. With the growth of Agentic AI and Large Language Models (LLMs), researchers are reusing this idea to build multi-agent systems. These systems use a mixture-of-experts (MoE) design, where different specialized agents or models work together to solve complex problems efficiently \cite{hanllm}

\subsubsection{Workflow}
A typical workflow starts with a Control Unit (CU),usually an LLM that decides which agents should handle the current task. Each agent processes part of the problem and writes its results to a shared blackboard memory. This shared memory lets every agent access the same information and build on each other’s work. The process continues until the system reaches a solution, either by agreement among agents or when a stopping condition is met \cite{hanllm}.

\subsubsection{Models Used}
Jacobs et al. \cite{amoe} first introduced the idea of adaptive mixtures of experts, where different models handle different tasks and their outputs are combined dynamically. Later, the sparsely-gated MoE layer \cite{omoe} improved the efficiency of very large neural networks. Recent studies \cite{smoe} have shown that MoE architectures help LLMs scale better, and Han and Zhang [14] found that combining them with blackboard coordination further improves reasoning and collaboration among agents.

In short, modern blackboard-based LLM multi-agent systems (bMAS) \cite{hanllm} combine the clear reasoning of early blackboard systems [10], the flexibility of mixtures of experts \cite{amoe}\cite{moe}, and the scalability seen in recent MoE research \cite{moe}\cite{smoe}.

\subsection{Blackboard}
The capabilities of a classical Blackboard Architecture allows researchers to take advantage of multi-agent systems in LLM-driven architectures\cite{nii1986blackboard}.
Agents enjoy flexible and competent workflows by making use of the information sharing and adaptive scheduling features of the blackboard. \cite{hanllm}.
Implementations of LbMAS have shown to be scalable and efficient. 


\subsubsection{Workflow}
The blackboard-based LLM multi-agent system (bMAS) undergoes one or more iterations during one problem solving session. 
Each iteration is an agent orchestration, managed by the Control Unit (CU)\cite{nii1986blackboard}. 
Each problem-solving session begins with agent generation, where an
expert skills required based on some query. The CU then selects appropriate agents based on the skills and provides them with the blackboard content. 
Agents consume and interpret this shared memory, perform computations, contribute their outputs back to the blackboard.
This whole process continues until some stopping condition is satisfied - either a consensus or a decider’s output or maximum rounds. \cite{hanllm}.  

\subsubsection{Models Used}
Classical Blackboard Architecture has three core components: (1) Control Unit (2) Blackboard (3) Knowledge Sources / Agents.
The control unit, which could also be an LLM, decides which skills and agents are required at a given stage \cite{hanllm}, thus ensuring efficiency and reducing token consumption. 
The blackboard functions as shared, persistent memory, with potential to be separated into public and private spaces, where oen or more agents record, debate, and refine their outputs \cite{nii1986blackboard}.  

Advanced agents are made capable of special roles like problem decomposition, evaluation of inconsistencies, or solution proposal. 
The whole system, given enough iterations, converges into one single solution.
\cite{hanllm}.


\section{System Design Architecture}
\begin{figure}
    \centering
    \includegraphics[width=1\linewidth]{overall-architecture.png}
    \caption{Overall System Architecture Diagram}
    \label{fig:placeholder}
\end{figure}
We aim to integrate the Blackboard Architecture (BA) into multi-agent systems (MASs) so that 
(1) agents with specific and unique skills / capabilities can share information during the problem-solving process
(2) decisions and actions taken by agents are based on the content of the blackboard at that time.

By allowing differents knowledge sources (agents) to communicate by the means of a common information field (blackboard), we create systems
capable of complex problem solving compared to traditional monolithic and sequencial systems.

We develop the first implementation of this proposal and conduct experiments on footages of Table Tennis gameplay. 
The overall system architecture / workflow is illustrated in Figure 1.

\subsection{Overview and Motivation}
The Blackboard Architecture was first proposed \cite{HAYESROTH1985251} \cite{PENNYNII199443} during early 1980s as a decentralized problem solving approach
that mimics human expertise collaborating around an actual blackboard, each contributing their own solution until the program is solved.

Employing a blackboard architecture in a Multi-Agent System (MAS) helps to take advantage of collective intelligence and 
thereby further enhancing problem-solving performance of the system.

\subsection{Core Components}
The BA itself relies on four core components: (1) Blackboard (2) Knowledge Source (3) Communication Interface (4) Control Unit (CU). Information from the Knowledge Sources are stored on the Blackboard and are being subsequently reused by other Knowledge Sources to iteratively approach a solution. 
\subsubsection{Blackboard}
The blackboard acts as a central, global data structure accessible by all modules (“knowledge sources”).
Each module posts intermediate or final results to the blackboard and reacts to changes made by other modules.
Communication and coordination are achieved indirectly by reading and writing to this shared resource, not through direct inter-module calls.

We have implemented the blackboard as different tables in a Relational Database (Postgres) for production grade data storage for relational data with faster retrievals and consistent read write operations.

The central database schema (see Tables I-VI) functions as the blackboard in our blackboard architecture implementation. 
All agents post their intermediate states, detected events, and final results solely into this schema, which defines the evolving solution space. 
This “single source of truth” approach ensures consistency, repeatability, and modularity: modules communicate solely through the blackboard and remain decoupled, except via well-defined database reads/writes. 

This aligns with classical blackboard systems, where the shared data structure orchestrates expert contributions and manages overall task progression.

% Table 1: table_tennis_analysis
\begin{table}[ht]
    \centering
    \caption{Schema of \texttt{table\_tennis\_analysis}}
    \label{tab:ttanalysis}
    \begin{tabular}{|l|l|l|}
        \hline
        \textbf{Column}        & \textbf{Type}    & \textbf{Description} \\
        \hline
        videoId                & INTEGER         & Unique video identifier \\
        frameId                & INTEGER         & Frame number within video \\
        frameAction            & VARCHAR         & Action detected in frame \\
        tableid                & INTEGER         & Table reference \\
        ballvisibility         & BOOLEAN         & Is ball visible? \\
        ballid                 & INTEGER         & Ball reference \\
        depthMapPath           & VARCHAR         & Path to depth map file \\
        ballbounce             & BOOLEAN         & Ball bounce event \\
        remarks                & VARCHAR         & Additional comments \\
        \hline
    \end{tabular}
\end{table}

% Table 2: table_coords
\begin{table}[ht]
    \centering
    \caption{Schema of \texttt{table\_coords}}
    \label{tab:tablecoords}
    \begin{tabular}{|l|l|l|}
        \hline
        \textbf{Column} & \textbf{Type} & \textbf{Description} \\
        \hline
        tableid   & INTEGER & Table identifier \\
        tablex1   & FLOAT   & \multirow{8}{*}{Table coordinates} \\
        tabley1   & FLOAT   &  \\
        tablex2   & FLOAT   &  \\
        tabley2   & FLOAT   &  \\
        tablex3   & FLOAT   &  \\
        tabley3   & FLOAT   &  \\
        tablex4   & FLOAT   &  \\
        tabley4   & FLOAT   &  \\
        \hline
    \end{tabular}
\end{table}

% Table 3: ball_data
\begin{table}[ht]
    \centering
    \caption{Schema of \texttt{ball\_data}}
    \label{tab:balldata}
    \begin{tabular}{|l|l|l|}
        \hline
        \textbf{Column} & \textbf{Type} & \textbf{Description} \\
        \hline
        ballId          & INTEGER       & Ball identifier \\
        ballx           & FLOAT         &  \\
        bally           & FLOAT         & Ball Position \\
        ballz           & FLOAT         &  \\
        ballxvector     & FLOAT         &  \\
        ballyvector     & FLOAT         & Ball Velocity \\
        ballzvector     & FLOAT         &  \\
        \hline
    \end{tabular}
\end{table}

% Table 4: player_positions
\begin{table}[ht]
    \centering
    \caption{Schema of \texttt{player\_positions}}
    \label{tab:playerpositions}
    \begin{tabular}{|l|l|l|}
        \hline
        \textbf{Column} & \textbf{Type} & \textbf{Description} \\
        \hline
        playerid        & INTEGER       & Player identifier \\
        playerx         & FLOAT         & \\
        playery         & FLOAT         & Player position \\
        playerz         & FLOAT         & \\
        \hline
    \end{tabular}
\end{table}

% Table 5: bounces
\begin{table}[ht]
    \centering
    \caption{Schema of \texttt{bounces}}
    \label{tab:bounces}
    \begin{tabular}{|l|l|l|}
        \hline
        \textbf{Column} & \textbf{Type} & \textbf{Description} \\
        \hline
        frameId         & INTEGER       & Frame identifier for bounce event \\
        ballId          & INTEGER       & Ball identifier for bounce event \\
        \hline
    \end{tabular}
\end{table}

% Table 6: video_table
\begin{table}[ht]
    \centering
    \caption{Schema of \texttt{video\_table}}
    \label{tab:videotable}
    \begin{tabular}{|l|l|l|}
        \hline
        \textbf{Column}           & \textbf{Type}    & \textbf{Description} \\
        \hline
        videoId                   & INTEGER         & Video identifier \\
        videoPath                 & VARCHAR         & Path to video file \\
        videoName                 & VARCHAR         & Name of video \\
        videoTag                  & VARCHAR         & Custom video tag/label \\
        fullvideoHeatmapPath      & VARCHAR         & Path to video heatmap \\
        videoDotMatrixSource      & VARCHAR         & Path/source for dot matrix map \\
        \hline
    \end{tabular}
\end{table}


\begin{figure}
    \centering
    \includegraphics[width=1\linewidth]{Component Interaction Diagram.png}
    \caption{Component Interaction Diagram. Abbreviation: MC = Message Callback; MQTT = Message Queuing Telemetry Transport;}
    \label{fig:placeholder}
\end{figure}
\subsubsection{Knowledge Sources}
The knowledge source is any set of functions that take some input and generate a result that brings the entire system one step closer to the solution. The input can either be raw data or an output of another knowledge source.
Each knowledge source ideally has a very specific set of skills that does not overlap with another.
The individual agents in our system, namely (1) Table Vertex Detection (2) Ball Position Detection (3) Player Heatmap Generation (4) Space Point Estimator and (5) Trajectory Analysis are the knowledge sources. 
These knowledge sources have been programmatically implemented as objects of their own classes, which are extended from an abstract class which has been illustrated in Figure 3.
We believe that this approach will contribute to the versatility, diversity and generality of agent introduction at scale.
\begin{figure}
    \centering
    \includegraphics[width=1\linewidth]{ClassDiagram.png}
    \caption{Class Diagram}
    \label{fig:placeholder}
\end{figure}
\subsubsection{Communication Interface}
The Communication Interface handles the communication between the knowledge sources and is based on the Publish Subscribe Model. This very model is the backbone behind BA, allowing agents share findings and results. 
We have implemented a Pub-Sub Model using RabbitMQ, an open-source message broker that enables reliable, asynchronous communication between distributed applications by queuing, routing, and delivering messages. Every knowledge source listens for tasks (messages) in a predefined queue and defines a \textit{callback-function}. 

CU places message on the appropriate queue, on behalf of agents, based on the skill required. Agents are triggered using the callback function when their queue gets a message. These agents perform requested operations on the blackboard and send a success message upon completion. 

\subsubsection{Control Unit}
The knowledge models are loosely coupled via task delegation to the CU. When the ball tracking model requires table coordinates, it submits the request to the CU, without needing awareness of which agent holds or computes this data. 
Since the CU is preconfigured with the list of knowledge sources, their skill sets, the IDs of the queue that they are listening to, it dynamically resolves and forwards this request to the appropriate agent, which processes and returns the result. 

This approach enables modularity and scalability by decoupling task requesters from the concrete implementers, following the orchestrator-worker pattern commonly employed in multi-agent and event-driven distributed systems

To enhance versatility and support dynamic integration of knowledge sources (agents), the control unit is designed to automatically extract and register the skill set and message queue information of each new consumer as it connects. 

This mechanism enables seamless discovery and on-the-fly integration of new capabilities, without requiring manual configuration or prior knowledge of the agent’s skills. As a result, the control unit serves as a dynamic registry, ensuring efficient routing of tasks based on updated agent capabilities as soon as they are available

\subsection{Component Description}
These are the knowledge sources that are incorporated into the overall system architecture
\subsubsection{Table Vertex Detection}
The results from this module is required by the trajectory analysis module and for answering certain questions by the answering machines.

\subsubsection{Ball Position Detection}
The ball detection module serves as a foundational constituent in the proposed table tennis analysis system.It enables precise localization of the ball across frames to facilitate analytics such as trajectory analysis. Accurate ball detection is essential for ensuring the reliability of subsequent modules that depend on spatial and temporal ball movement data.
\subsubsection{Player Heatmap Generation}
The player heatmap is a useful tool for user analysis as it shows the behaviour and preferred styles of each player. It provides the positions of each player on every frame using a simple pretrained YOLO model 
\subsubsection{Space Point Estimator}
The space point estimator adds an extra layer of insight as it can convert points on a 2D video into 3D coordinates. 
\subsubsection{Trajectory Analysis}
The trajectory analysis component delivers accurate ball tracking and motion analysis from high-frame-rate table tennis videos. It automatically extracts the ball’s spatial positions, velocities, and bounce points with high precision, supporting both tactical coaching and detailed player performance evaluation.

\section{Implementation}

\subsection{Table Vertex Detection}
This is a crucial model for several other deeper analysis as it provides a sense of space to the 2D video which is useful for trajectory analysis, 3D analysis and certain types of questions.
Following the work done by Haas et al., we first tried Hough Transforms and image processing to find the table coordinates. However this ran into many issues,
\begin{itemize}
\item For many videos the edge detection had too many gaps and smoothing was not enough to fix the images well enough for hough transformation to work
\begin{figure}[h!]
    \centering
    \includegraphics[width=1\linewidth]{5.1.png}
    \caption{Issues due to gaps in edge detection due to player interference}
    \label{fig:placeholder}
\end{figure}
\item Small disturbances could cause the table to be detected very wrongly
\item The lines on the table could cause issues with the table detection
\item The image processing was such that it could be made to work for some cases but only at the cost of others
\end{itemize}

% \begin{figure}[h!]
%     \centering
%     \includegraphics[width=1\linewidth]{5.2.png}
%     \caption{Issues due to lines on the table}
%     \label{fig:placeholder}
% \end{figure}

These issues led to moving towards a more general deep learning pipeline using YOLO. We used a YOLOv8 pose estimation model trained on custom manually and synthetically generated data from the dataset. The pose estimation did not work well with the amount of data present in the dataset. However, the bounding boxes worked well and were used in the final system. The YOLO model was wrapped in a function

\begin{figure}[h!]
    \centering
    \includegraphics[width=1\linewidth]{5.3.png}
    \caption{Final YOLO Implementation of Table Detection}
    \label{fig:placeholder}
\end{figure}

\subsection{Ball Position Detection}
The YOLOv11n model was chosen for this task because it is lightweight and good at spotting small and fast-moving objects; i,e. A table tennis ball. A large-scale dataset comprising approximately 88,599 annotated frames was used for model training in the initial stage.However, due to the high computational requirements and limited GPU resources in Google Colab, the complete dataset could not be processed efficiently. To address this, 6,721 frames containing the ball were extracted and used for training. This approach resulted in high loss values, primarily due to the lack of negative samples representing non-ball instances. To help the model learn better, a balanced dataset was made with 6,721 ball frames and 2,700 frames with no ball. This helped improve recall and made training faster. 

\begin{figure}[h!]
    \centering
    \includegraphics[width=1\linewidth]{5.4.jpg}
    \caption{Ball Position Detection}
    \label{fig:placeholder}
\end{figure}

\subsection{Trajectory Analysis}
\subsubsection{Framewise Ball Position Detection}
This data is collected from the blackboard and is computed by the Ball Position Detection Module. This step is the backbone sequence of ball locations.

\subsubsection{Interpolation}
Often, sports videos have moments where the ball is not detected, that even advanced models can lose track of it a few times. To maintain the path continuity and prevent analytical errors, the pipeline significantly identifies such missing spaces in detection. For gaps no larger than a particular threshold (e.g., 5 frames), the system applies
cubic spline interpolation to fill in the missing details


\begin{itemize}
    \item Identify all consecutive frames where the position data is missing 

    \item For gaps that are surrounded by valid positions, fill in the missing points using a cubic spline curve, ensuring the trajectory remains smooth and continuous.

\end{itemize}

\subsubsection{Kalman Filter and Smoothing}
The raw or interpolated ball positions still include some noise, that is caused by imperfect detections or changes in the environment. To address this, Kalman filter is applied. The filter tracks the movement of the ball  and combines the predicted movement (based on physics) with the actual which is sometimes noisy.


\begin{itemize}
    \item The initial ball position is determined from the earliest available frames.
    \item The filter parameters, such as process and measurement noise, are adjusted according to the video’s resolution, frame rate, and the expected motion behavior of the ball.
\end{itemize}

\subsubsection{Bounce Points Detection}
Bounces are key features in table tennis analysis. The system looks at the smoothed y-coordinates to detect drops near the table surface that indicate possible bounce. To distinguish real bounces from noise, it also checks for a change in the sign of the vertical velocity,which is a strong indicator that the ball has hit the surface and reversed the  direction.

\begin{itemize}
    \item For each frame, compare its y-value with neighboring frames (i-1, i, i+1) to find local minima that may represent bounces.

    \item Verify a change in sign confirms a reversal in motion.

    \item Only consider frames within a set vertical range as valid bounce candidates.

\end{itemize}

% \subsubsection{Bounce Correction}
% The detected bounce points usually may not perfectly align with the actual table coordinates due to very small detection errors or video noise. In order to correct this, bounce points that are close to the table surface are adjusted to match the exact y-coordinate of the nearest table edge (top or bottom). 


\subsubsection{Velocity Computation}
The ball’s velocity information is crucial to analyze the ball’s motion, . This system computes the velocity after smoothing the path of the ball, through the numerical gradient of its x and y position values for each frame. This gives both horizontal and vertical components of the velocity, namely ($ball _x vector$) and ($ball _yvector$)
\begin{figure}[h!]
    \centering
    \includegraphics[width=1\linewidth]{5.5.jpg}
    \caption{Path generated by Trajectory Analysis}
    \label{fig:placeholder}
\end{figure}

\subsection{Space Point Estimator}

The main objective or intention of the Space Point Estimator module is to transform 2D points captured from table tennis video frames into 3D coordinates of the world. Doing this facilitates more detailed and precise analytics throughout the system. This transformation is done using advanced depth estimation with the Depth Anything V2 model.


\subsubsection{Workflow and Process}

When preparing a frame (image) for depth estimation such as a video frame where table positions or ball positions are identified, the image path is submitted to the estimator. 

The steps of the process are:


\begin{itemize}
    \item \textbf{Image Input and Preprocessing:} 
    The estimator takes the video frame path, loads the image, converts into a standard RGB format, and its dimensions are stored.

    
    \item \textbf{Depth Anything V2 Model Inference:}
   The heart of the system is the Depth Anything V2 model.It is a transformer based architecture, pre-trained to figure out the depth from a camera angle. Before processing, the image is converted into tensors with which the model works.The model generates a dense depth map, which illustrates per-pixel distance estimations within the scene.

    
    % \item \textbf{Caching for Efficiency:}
    % To avoid repeating the calculations for images that are processed often, the model saves each image’s depth map using an MD5 hash of the image file. When the same image is requested again, the result that is stored already is retrieved from the cache instead of recalculating it.


    \item \textbf{Depth Map Normalization \& Scaling:}
   The depth map is first normalized, based on the minimum and maximum depths within the map. After normalization, it is scaled to a specific metric range (for example, up to 1499 mm) to suit the requirements of the table tennis analysis.

    \item \textbf{Sub-Pixel 3D Coordinate Retrieval:}
    For any $(x, y)$ pixel coordinate in the image like the position of a ball or player, the system uses bilinear interpolation on the depth map to estimate a precise Z (depth) value.


    \item \textbf{Output:}
    The resulting $(x, y, z)$ coordinate of the requested point can now be directly translated into real-world 3D space.
\end{itemize}
% \subsubsection{Sample Process Flow}

% The method \texttt{getzpointfromxandy()} is invoked with an image (for instance, the annotated frame) and specified pixel coordinates.

% The estimator either loads or retrieves the corresponding depth map for that image.

% Bilinear interpolation is executed on the depth map utilizing the provided $x$ and $y$ coordinates, resulting in a highly accurate depth ($z$) value.

% The resulting $(x, y, z)$ triplet signifies authentic 3D positions, effectively addressing the intrinsic limitations of 2D video footage.

\begin{figure}
    \centering
    \includegraphics[width=1\linewidth]{fixed_depth_result.png}
    \caption{Depth distribution and inverted depth map produced by the Space Point Estimator.}
    \label{fig:placeholder}
\end{figure}

% \subsubsection{System Integration}

% Within the agentic system, this module functions as a Knowledge Source, supplying 3D information upon demand. Its output is uploaded to the blackboard database, where other agents—such as those responsible for trajectory or bounce analysis—can integrate depth-enhanced data to accomplish spatial and reasoning tasks that were previously unattainable. This facilitates precise coaching feedback, improved trajectory correction, and more comprehensive tactical insights for table tennis analytics.

\section{Experimental Results}
Every module has to be evaluated differently due to the varying nature of our Knowledge Sources. Some are ML models while others are simple data and image processing. The performance metrics of the Knowledge Sources are given below

\subsection{Table Vertex Detection}
Here, 2 metrics were employed, Bounding Box Overlap, which checks the area of the predicted box that covers the actual object and a custom metric. Metrics such as Precision and Recall aren't informative as the final usage comes from an average over many frames so model performance over individual frames are not used

The custom metric, denoted as Shape Error is used to check the variance in the corner positions predicted by the model scaled against the size of the table in meters. We use these custom metrics as they are more suited to how we actually use the results of this model

\begin{table}[ht]
    \centering
    \caption{Results of  \texttt{Table\_Vertex\_Detection}}
    \label{tab:ttanalysis}
    \begin{tabular}{|l|l|}
        \hline
        \textbf{Metric}        & \textbf{Error}    \\
        \hline
        Overlap                &  0.6761           \\
        Shape Error                & 3.5038          \\
        \hline
    \end{tabular}
\end{table}

\subsection{Ball Position Detection}

Here we use normal metrics such as Precision and Recall along with certain YOLO-specific metrics such as mAP50 and mAP95

\begin{table}[ht]
    \centering
    \caption{Results of  \texttt{Ball\_Position\_Detection}}
    \label{tab:ttanalysis}
    \begin{tabular}{|l|l|}
        \hline
        \textbf{Metric}        & \textbf{Error}    \\
        \hline
        Precision                &  0.9043           \\
        Recall                & 0.8622          \\
        mAP50                & 0.9457          \\
        mAP50-95                & 0.6136          \\
        
        \hline
    \end{tabular}
\end{table}
\begin{figure}[h!]
    \centering
    \includegraphics[width=1\linewidth]{confusion_matrix.png}
    \caption{Confusion Matrix for Ball Position Detection}
    \label{fig:placeholder}
\end{figure}

From these metrics we can understand that this model has a very high precision value and can 
accurately predict where the ball is. While it does have some false negative, the trajectory analysis 
module can interpolate and compensate for any missing data 

\subsection{Depth Estimation}
\begin{figure}[h!]
    \centering
    \includegraphics[width=1\linewidth]{depth1.png}
    \caption{Depth Anything V2 pixels processed per second }
    \label{fig:placeholder}
\end{figure}
This metric shows the models processing throughput, scalability to higher resolution, hardware utilization and optimization on frequent access, the real time processing capability of the model. This shows that if the model is loaded it can process various image in that instance at low time making it suitable for video frames to 3d frame applications.

\begin{figure}[h!]
    \centering
    \includegraphics[width=1\linewidth]{depth2.png}
    \caption{Depth Anything V2 Detail score per image}
    \label{fig:placeholder}
\end{figure}
The detail score shows the capability of the model on how well it estimates the depth map while retaining fine structural details and edges. It is computed by the change in the spatial gradient values, with higher score meaning better detail preservation of the object boundary


\begin{figure}[h!]
    \centering
    \includegraphics[width=1\linewidth]{depth3.png}
    \caption{Depth Anything overall quality per image}
    \label{fig:placeholder}
\end{figure}
The overall quality score indicates the evaluation of depth map by combing depth range, detail preservation, and consistency. This output shows the practical usefulness in the sense of maintaining higher detail and accuracy on the 3d depth map .

% \begin{figure}[htbp]
% \centerline{\includegraphics{fig1.png}}
% \caption{Example of a figure caption.}
% \label{fig}
% \end{figure}
\section{Future Work}
The Multi-Agent System proposed here operates on static, preconfigured blackboard architecture, which almost often requires manual construction and thus lacks generality.
Recent studies on LLM Based Multi-Agent System (LbMAS) \cite{hanllm} develop autonomous MASs by taking advantage of using a Large Language Model as the control unit. 
These LLMs can be used to dynamically configure new agents and their skills in runtime, make it much more general and requiring low to none manual setup.
While, in theory, a static agent configuration is quicker and deterministic, the generality of a dynamic MAS outweighs those disadvantages.  
In an age of rapid Cloud and Distributed Computing evolution, our proposal could also be made to leverage remote knowledge sources/agents and remote computing resources over a distributed network. 
Recent studies \cite{agentworkfloworchetration} \cite{distributedblackboard} show promising implementations of MASs with many agents running on different networks/systems.
Our idea of a highly scalable MAS lies behind the ability to orchestrate and manage each type of knowledge source, individually, using a control unit of its own, taking inspiration from Kubernetes.

% \section{Acknowledgement}
% content
\bibliographystyle{plain} % or 'unsrt', 'abbrv', etc.
\nocite{*}
\bibliography{references}

\end{document}
